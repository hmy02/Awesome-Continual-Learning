# Awesome-Continual-Learning

This is the paper list of our paper ``A Comprehensive Survey of Continual Learning: Theory, Method and Application''.


## Survey

- <a name="todo"></a> [2023 arXiv] A Comprehensive Survey of Continual Learning: Theory, Method and Application [[paper](https://arxiv.org/abs/2302.00487)]
  
- <a name="todo"></a> [2023 arXiv] A Survey on Incremental Update for Neural Recommender Systems [[paper](https://arxiv.org/abs/2303.02851#)]
  
- <a name="todo"></a> [2023 arXiv] Deep Class-Incremental Learning: A Survey [[paper](https://arxiv.org/abs/2302.03648)]

- <a name="todo"></a> [2023 arXiv] Towards Label-Efficient Incremental Learning A Survey [[paper](https://arxiv.org/abs/2302.00353)]

- <a name="todo"></a> [2022 arXiv] Continual Learning of Natural Language Processing Tasks A Survey [[paper](https://arxiv.org/abs/2211.12701)]
  
- <a name="todo"></a> [2022 Trends in Neurosciences] Contributions by metaplasticity to solving the Catastrophic Forgetting Problem [[paper](https://doi.org/10.1016/j.tins.2022.06.002)]

- <a name="todo"></a> [2022 TPAMI] Class-incremental learning survey and performance evaluation on image classification [[paper](https://arxiv.org/abs/2010.15277)]

- <a name='todo'></a> [2022 NMI] Biological underpinnings for lifelong learning machines [[paper](https://www.nature.com/articles/s42256-022-00452-0)]

- <a name='todo'></a> [2022 Neurocomputing] Online Continual Learning in Image Classification_ An Empirical Survey [[paper](https://arxiv.org/abs/2101.10423)]

- <a name='todo'></a> [2022 JAIR] Towards Continual Reinforcement Learning [[paper](https://arxiv.org/abs/2012.13490)]

- <a name='todo'></a> [2021 arXiv] Recent Advances of Continual Learning in Computer Vision_ An Overview [[paper](https://arxiv.org/abs/2109.11369)]

- <a name='todo'></a> [2021 TPAMI] A continual learning survey_ Defying forgetting in classification tasks [[paper](https://arxiv.org/abs/1909.08383)]

- <a name='todo'></a> [2021 Neural Computation] Replay in Deep Learning_ Current Approaches and Missing Biological Elements [[paper](https://arxiv.org/abs/2104.04132)]

- <a name='todo'></a> [2020 Trends in Cognitive Sciences] Embracing Change_ Continual Learning in Deep Neural Networks [[paper](https://www.sciencedirect.com/science/article/pii/S1364661320302199)]

- <a name='todo'></a> [2020 TPAMI] Class-incremental learning survey and performance evaluation on image classification [[paper](https://arxiv.org/abs/2010.15277)]

- <a name='todo'></a> [2020 COLING] Continual Lifelong Learning in Natural Language Processing_ A Survey [[paper](https://arxiv.org/abs/2012.09823)]
  
- <a name="todo"></a> [2019 Neural Networks] Continual Lifelong Learning with Neural Networks: A Review [[paper](https://arxiv.org/abs/1802.07569)]


## Papers

### 2023

- <a name='todo'></a> [2023 ICLR] Task-Aware Information Routing from Common Representation Space in Lifelong Learning [[paper](https://arxiv.org/abs/2302.11346)]

### 2022

- <a name='todo'></a> [2022 WACV] Online Continual Learning Via Candidates Voting [[paper](https://arxiv.org/abs/2110.08855v1)]

- <a name='todo'></a> [2022 WACV] Knowledge Capture and Replay for Continual Learning [[paper](https://arxiv.org/abs/2012.06789)]

- <a name='todo'></a> [2022 WACV] FeTrIL Feature Translation for Exemplar-Free Class-Incremental Learning [[paper](https://arxiv.org/abs/2211.13131)]

- <a name='todo'></a> [2022 WACV] Dataset Knowledge Transfer for Class-Incremental Learning without Memory [[paper](https://arxiv.org/abs/2110.08421)]

- <a name='todo'></a> [2022 TPAMI] Uncertainty-aware Contrastive Distillation for Incremental Semantic Segmentation [[paper](https://arxiv.org/abs/2203.14098)]

- <a name='todo'></a> [2022 TPAMI] MgSvF Multi-Grained Slow vs. Fast Framework for Few-Shot Class-Incremental Learning [[paper](https://arxiv.org/abs/2006.15524)]

- <a name='todo'></a> [2022 TPAMI] Few-Shot Class-Incremental Learning by Sampling Multi-Phase Tasks [[paper](https://arxiv.org/abs/2203.17030)]

- <a name='todo'></a> [2022 TPAMI] Class-Incremental Continual Learning into the eXtended DER-verse [[paper](https://arxiv.org/abs/2201.00766)]

- <a name='todo'></a> [2022 TNNLS] Self-Training for Class-Incremental Semantic Segmentation [[paper](https://arxiv.org/abs/2012.03362)]

- <a name='todo'></a> [2022 PRL] Continual Semi-Supervised Learning through Contrastive Interpolation Consistency  [[paper](https://arxiv.org/abs/2108.06552)]

- <a name='todo'></a> [2022 NeurIPS] Task-Free Continual Learning via Online Discrepancy Distance Learning [[paper](https://arxiv.org/abs/2210.06579)]

- <a name='todo'></a> [2022 NeurIPS] SparCL Sparse Continual Learning on the Edge [[paper](https://arxiv.org/abs/2209.09476)]

- <a name='todo'></a> [2022 NeurIPS] S-Prompts Learning with Pre-trained Transformers An Occam’s Razor for Domain Incremental Learning [[paper](https://arxiv.org/abs/2207.12819)]

- <a name='todo'></a> [2022 NeurIPS] Retrospective Adversarial Replay for Continual Learning [[paper](https://openreview.net/forum?id=XEoih0EwCwL)]

- <a name='todo'></a> [2022 NeurIPS] Repeated Augmented Rehearsal A Simple but Strong Baseline for Online Continual Learning [[paper](https://arxiv.org/abs/2209.13917)]

- <a name='todo'></a> [2022 NeurIPS] On the Effectiveness of Lipschitz-Driven Rehearsal in Continual Learning [[paper](https://arxiv.org/abs/2210.06443)]

- <a name='todo'></a> [2022 NeurIPS] On Reinforcement Learning and Distribution Matching for Fine-Tuning Language Models with no Catastrophic Forgetting [[paper](https://arxiv.org/abs/2206.00761)]

- <a name='todo'></a> [2022 NeurIPS] Memory Efficient Continual Learning with Transformers [[paper](https://arxiv.org/abs/2203.04640)]

- <a name='todo'></a> [2022 NeurIPS] Margin-Based Few-Shot Class-Incremental Learning with Class-Level Overfitting Mitigation [[paper](https://arxiv.org/abs/2210.04524)]

- <a name='todo'></a> [2022 NeurIPS] Lifelong Neural Predictive Coding: Learning Cumulatively Online without Forgetting [[paper](https://arxiv.org/abs/1905.10696)]

- <a name='todo'></a> [2022 NeurIPS] How Well Do Unsupervised Learning Algorithms Model Human Real-time and Life-long Learning [[paper](https://openreview.net/forum?id=c0l2YolqD2T)]

- <a name='todo'></a> [2022 NeurIPS] Few-Shot Continual Active Learning by a Robot [[paper](https://arxiv.org/abs/2210.04137)]

- <a name='todo'></a> [2022 NeurIPS] Exploring Example Influence in Continual Learning [[paper](https://arxiv.org/abs/2209.12241)]

- <a name='todo'></a> [2022 NeurIPS] Disentangling Transfer in Continual Reinforcement Learning [[paper](https://arxiv.org/abs/2209.13900)]

- <a name='todo'></a> [2022 NeurIPS] Continual Learning In Environments With Polynomial Mixing Times [[paper](https://arxiv.org/abs/2112.07066)]

- <a name='todo'></a> [2022 NeurIPS] Continual learning a feature extraction formalization, an efficient algorithm, and fundamental obstructions [[paper](https://arxiv.org/abs/2203.14383)]

- <a name='todo'></a> [2022 NeurIPS] CLiMB A Continual Learning Benchmark for Vision-and-Language Tasks [[paper](https://arxiv.org/abs/2206.09059)]

- <a name='todo'></a> [2022 NeurIPS] CGLB Benchmark Tasks for Continual Graph Learning [[paper](https://openreview.net/forum?id=5wNiiIDynDF)]

- <a name='todo'></a> [2022 NeurIPS] Beyond Not-Forgetting Continual Learning with Backward Knowledge Transfer [[paper](https://arxiv.org/abs/2211.00789)]

- <a name='todo'></a> [2022 NeurIPS] ALIFE Adaptive Logit Regularizer and Feature Replay for Incremental Semantic Segmentation [[paper](https://arxiv.org/abs/2210.06816)]

- <a name='todo'></a> [2022 NeurIPS] A Theoretical Study on Solving Continual Learning [[paper](https://arxiv.org/abs/2211.02633)]

- <a name='todo'></a> [2022 NeurIPSW] A Simple Baseline that Questions the Use of Pretrained-Models in Continual Learning [[paper](https://arxiv.org/abs/2210.04428)]

- <a name='todo'></a> [2022 Neural Networks] Efficient Perturbation Inference and Expandable Network for Continual Learning [[paper](https://www.sciencedirect.com/science/article/abs/pii/S0893608022004269)]

- <a name='todo'></a> [2022 NAACL] Overcoming Catastrophic Forgetting During Domain Adaptation of Seq2seq Language Generation [[paper](https://aclanthology.org/2022.naacl-main.398.pdf)]

- <a name='todo'></a> [2022 MM] Semantics-Driven Generative Replay for Few-Shot Class Incremental Learning [[paper](https://doi.org/10.1145/3503161.3548160)]

- <a name='todo'></a> [2022 MM] Incremental Few-Shot Semantic Segmentation via Embedding Adaptive-Update and Hyper-class Representation [[paper](https://arxiv.org/abs/2207.12964)]

- <a name='todo'></a> [2022 MM] Class Gradient Projection For Continual Learning [[paper](https://doi.org/10.1145/3503161.3548054)]

- <a name='todo'></a> [2022 IJCAI] Learning from Students_ Online Contrastive Distillation Network for General Continual Learning [[paper](https://doi.org/10.24963/ijcai.2022/446)]

- <a name='todo'></a> [2022 IJCAI] DyGRAIN_ An Incremental Learning Framework for Dynamic Graphs [[paper](https://doi.org/10.24963/ijcai.2022/438)]

- <a name='todo'></a> [2022 IJCAI] Continual Semantic Segmentation Leveraging Image-level Labels and Rehearsal [[paper](https://doi.org/10.24963/ijcai.2022/177)]

- <a name='todo'></a> [2022 IJCAI] Continual Federated Learning Based on Knowledge Distillation [[paper](https://doi.org/10.24963/ijcai.2022/303)]

- <a name='todo'></a> [2022 IJCAI] CERT_ Continual Pre-Training on Sketches for Library-Oriented Code Generation [[paper](https://doi.org/10.24963/ijcai.2022/329)]

- <a name='todo'></a> [2022 ICPR] Effects of Auxiliary Knowledge on Continual Learning [[paper](https://arxiv.org/abs/2206.02577v1)]

- <a name='todo'></a> [2022 ICML] Wide Neural Networks Forget Less Catastrophically [[paper](https://arxiv.org/abs/2110.11526)]

- <a name='todo'></a> [2022 ICML] Wide Neural Networks Forget Less Catastrophically [[paper](https://arxiv.org/abs/2110.11526)]

- <a name='todo'></a> [2022 ICML] VariGrow_ Variational Architecture Growing for Task-Agnostic Continual Learning based on Bayesian Novelty [[paper](https://proceedings.mlr.press/v162/ardywibowo22a.html)]

- <a name='todo'></a> [2022 ICML] Proving Theorems using Incremental Learning and Hindsight Experience Replay [[paper](https://arxiv.org/abs/2112.10664)]

- <a name='todo'></a> [2022 ICML] Online Continual Learning through Mutual Information Maximization [[paper](https://proceedings.mlr.press/v162/guo22g.html)]

- <a name='todo'></a> [2022 ICML] NISPA_ Neuro-Inspired Stability-Plasticity Adaptation for Continual Learning in Sparse Networks [[paper](https://arxiv.org/abs/2206.09117)]

- <a name='todo'></a> [2022 ICML] Improving Task-free Continual Learning by Distributionally Robust Memory Evolution [[paper](https://arxiv.org/abs/2207.07256)]

- <a name='todo'></a> [2022 ICML] Forget-free Continual Learning with Winning Subnetworks [[paper](https://arxiv.org/abs/2303.14962)]

- <a name='todo'></a> [2022 ICML] Continual Learning with Guarantees via Weight Interval Constraints [[paper](https://arxiv.org/abs/2206.07996)]

- <a name='todo'></a> [2022 ICML] Continual Learning via Sequential Function-Space Variational Inference [[paper](https://proceedings.mlr.press/v162/rudner22a.html)]

- <a name='todo'></a> [2022 ICLR] TRGP: Trust Region Gradient Projection for Continual Learning [[paper](https://arxiv.org/abs/2202.02931)]

- <a name='todo'></a> [2022 ICLR] Towards Continual Knowledge Learning of Language Models [[paper](https://arxiv.org/abs/2110.03215)]

- <a name='todo'></a> [2022 ICLR] Subspace Regularizers for Few-Shot Class Incremental Learning [[paper](https://arxiv.org/abs/2110.07059)]

- <a name='todo'></a> [2022 ICLR] Representational Continuity for Unsupervised Continual Learning [[paper](https://arxiv.org/abs/2110.06976)]

- <a name='todo'></a> [2022 ICLR] Pretrained Language Model in Continual Learning: A Comparative Study [[paper](https://openreview.net/forum?id=figzpGMrdD)]

- <a name='todo'></a> [2022 ICLR] Online Coreset Selection for Rehearsal-based Continual Learning [[paper](https://arxiv.org/abs/2106.01085)]

- <a name='todo'></a> [2022 ICLR] Online Continual Learning on Class Incremental Blurry Task Configuration with Anytime Inference [[paper](https://arxiv.org/abs/2110.10031)]

- <a name='todo'></a> [2022 ICLR] New Insights on Reducing Abrupt Representation Change in Online Continual Learning [[paper](https://arxiv.org/abs/2104.05025)]

- <a name='todo'></a> [2022 ICLR] New Insights on Reducing Abrupt Representation Change in Online Continual Learning [[paper](https://arxiv.org/abs/2104.05025)]

- <a name='todo'></a> [2022 ICLR] Model Zoo A Growing “Brain” That Learns Continually [[paper](https://arxiv.org/abs/2106.03027)]

- <a name='todo'></a> [2022 ICLR] Memory Replay with Data Compression for Continual Learning [[paper](https://arxiv.org/abs/2202.06592)]

- <a name='todo'></a> [2022 ICLR] Looking Back on Learned Experiences For Class/task Incremental Learning [[paper](https://openreview.net/forum?id=RxplU3vmBx)]

- <a name='todo'></a> [2022 ICLR] LFPT5: A Unified Framework for Lifelong Few-shot Language Learning Based on Prompt Tuning of T5 [[paper](https://arxiv.org/abs/2110.07298)]

- <a name='todo'></a> [2022 ICLR] Learning Fast, Learning Slow: A General Continual Learning Method based on Complementary Learning System [[paper](https://arxiv.org/abs/2201.12604)]

- <a name='todo'></a> [2022 ICLR] Learning Curves for Continual Learning in Neural Networks: Self-Knowledge Transfer and Forgetting [[paper](https://arxiv.org/abs/2112.01653)]

- <a name='todo'></a> [2022 ICLR] Information-theoretic Online Memory Selection for Continual Learning [[paper](https://arxiv.org/abs/2204.04763)]

- <a name='todo'></a> [2022 ICLR] How Well Does Self-Supervised Pre-Training Perform with Streaming Data? [[paper](https://arxiv.org/abs/2104.12081)]

- <a name='todo'></a> [2022 ICLR] Effect of Scale on Catastrophic Forgetting in Neural Networks [[paper](https://openreview.net/forum?id=GhVS8_yPeEa)]

- <a name='todo'></a> [2022 ICLR] Continual Normalization: Rethinking Batch Normalization for Online Continual Learning [[paper](https://arxiv.org/abs/2203.16102)]

- <a name='todo'></a> [2022 ICLR] Continual Learning with Recursive Gradient Optimization [[paper](https://arxiv.org/pdf/2201.12522.pdf)]

- <a name='todo'></a> [2022 ICLR] Continual Learning with Filter Atom Swapping  [[paper](https://openreview.net/forum?id=metRpM4Zrcb)]

- <a name='todo'></a> [2022 ICLR] CoMPS: Continual Meta Policy Search [[paper](https://arxiv.org/abs/2112.04467)]

- <a name='todo'></a> [2022 ICLR] CLEVA-Compass: A Continual Learning EValuation Assessment Compass to Promote Research Transparency and Comparability [[paper](https://arxiv.org/abs/2110.03331)]

- <a name='todo'></a> [2022 EMNLP] Continual Training of Language Models for Few-Shot Learning [[paper](https://arxiv.org/abs/2210.05549)]

- <a name='todo'></a> [2022 ECCV] Transfer without Forgetting [[paper](https://arxiv.org/abs/2206.00388)]

- <a name='todo'></a> [2022 ECCV] The Challenges of Continuous Self-Supervised Learning [[paper](https://arxiv.org/abs/2203.12710)]

- <a name='todo'></a> [2022 ECCV] S3C Self-Supervised Stochastic Classifiers for Few-Shot Class-Incremental Learning [[paper](https://arxiv.org/abs/2307.02246)]

- <a name='todo'></a> [2022 ECCV] R-DFCIL Relation-Guided Representation Learning for Data-Free Class Incremental Learning [[paper](https://arxiv.org/abs/2203.13104)]

- <a name='todo'></a> [2022 ECCV] Prototype-Guided Continual Adaptation for Class-Incremental Unsupervised Domain Adaptation [[paper](https://arxiv.org/abs/2207.10856)]

- <a name='todo'></a> [2022 ECCV] Online Task-free Continual Learning with Dynamic Sparse Distributed Memory [[paper](https://doi.org/10.1007/978-3-031-19806-9_42)]

- <a name='todo'></a> [2022 ECCV] Online Continual Learning with Contrastive Vision Transformer [[paper](https://arxiv.org/abs/2207.13516)]

- <a name='todo'></a> [2022 ECCV] Novel Class Discovery without Forgetting [[paper](http://arxiv.org/abs/2207.10659)]

- <a name='todo'></a> [2022 ECCV] Meta-Learning with Less Forgetting on Large-Scale Non-Stationary Task Distributions [[paper](https://arxiv.org/abs/2209.01501)]

- <a name='todo'></a> [2022 ECCV] Long-Tailed Class Incremental Learning [[paper](https://arxiv.org/abs/2210.00266)]

- <a name='todo'></a> [2022 ECCV] Learning with Recoverable Forgetting [[paper](https://arxiv.org/abs/2207.08224)]

- <a name='todo'></a> [2022 ECCV] Incremental Task Learning with Incremental Rank Updates [[paper](https://arxiv.org/abs/2207.09074)]

- <a name='todo'></a> [2022 ECCV] incDFM Incremental Deep Feature Modeling for Continual Novelty Detection [[paper](https://doi.org/10.1007/978-3-031-19806-9_34)]

- <a name='todo'></a> [2022 ECCV] Helpful or Harmful Inter-Task Association in Continual Learning [[paper](https://doi.org/10.1007/978-3-031-20083-0_31)]

- <a name='todo'></a> [2022 ECCV] Generative Negative Text Replay for Continual Vision-Language Pretraining [[paper](https://arxiv.org/abs/2210.17322)]

- <a name='todo'></a> [2022 ECCV] FOSTER Feature Boosting and Compression for Class-Incremental Learning [[paper](https://arxiv.org/abs/2204.04662)]

- <a name='todo'></a> [2022 ECCV] Few-Shot Class-Incremental Learning via Entropy-Regularized Data-Free Replay [[paper](https://arxiv.org/abs/2207.11213)]

- <a name='todo'></a> [2022 ECCV] Few-Shot Class-Incremental Learning from an Open-Set Perspective [[paper](https://arxiv.org/abs/2208.00147)]

- <a name='todo'></a> [2022 ECCV] DualPrompt Complementary Prompting for Rehearsal-free Continual Learning [[paper](https://arxiv.org/abs/2204.04799)]

- <a name='todo'></a> [2022 ECCV] DLCFT Deep Linear Continual Fine-Tuning for General Incremental Learning [[paper](https://arxiv.org/abs/2208.08112)]

- <a name='todo'></a> [2022 ECCV] CoSCL Cooperation of Small Continual Learners is Stronger than a Big One [[paper](https://arxiv.org/abs/2207.06543)]

- <a name='todo'></a> [2022 ECCV] Class-incremental Novel Class Discovery [[paper](https://arxiv.org/abs/2207.08605)]

- <a name='todo'></a> [2022 ECCV] Class-Incremental Learning with Cross-Space Clustering and Controlled Transfer [[paper](https://arxiv.org/abs/2208.03767)]

- <a name='todo'></a> [2022 ECCV] Balancing Stability and Plasticity through Advanced Null Space in Continual Learning [[paper](https://arxiv.org/abs/2207.12061)]

- <a name='todo'></a> [2022 ECCV] Balancing between Forgetting and Acquisition in Incremental Subpopulation Learning [[paper](https://doi.org/10.1007/978-3-031-19809-0_21)]

- <a name='todo'></a> [2022 ECCV] Anti-Retroactive Interference for Lifelong Learning [[paper](https://arxiv.org/abs/2208.12967)]

- <a name='todo'></a> [2022 CVPR] vCLIMB A Novel Video Class Incremental Learning Benchmark [[paper](https://arxiv.org/abs/2201.09381)]

- <a name='todo'></a> [2022 CVPR] Towards Better Plasticity-Stability Trade-off in Incremental Learning A Simple Linear Connector [[paper](https://arxiv.org/abs/2110.07905)]

- <a name='todo'></a> [2022 CVPR] Self-Sustaining Representation Expansion for Non-Exemplar Class-Incremental Learning [[paper](https://arxiv.org/abs/2203.06359)]

- <a name='todo'></a> [2022 CVPR] Self-Supervised Models are Continual Learners [[paper](https://arxiv.org/abs/2112.04215)]

- <a name='todo'></a> [2022 CVPR] Representation Compensation Networks for Continual Semantic Segmentation [[paper](https://arxiv.org/abs/2203.05402)]

- <a name='todo'></a> [2022 CVPR] Probing Representation Forgetting in Supervised and Unsupervised Continual Learning [[paper](https://arxiv.org/abs/2203.13381)]

- <a name='todo'></a> [2022 CVPR] Overcoming Catastrophic Forgetting in Incremental Object Detection via Elastic Response Distillation [[paper](https://arxiv.org/abs/2204.02136)]

- <a name='todo'></a> [2022 CVPR] Online Continual Learning on a Contaminated Data Stream with Blurry Task Boundaries [[paper](https://arxiv.org/abs/2203.15355)]

- <a name='todo'></a> [2022 CVPR] On Generalizing Beyond Domains in Cross-Domain Continual Learning [[paper](https://arxiv.org/abs/2203.03970)]

- <a name='todo'></a> [2022 CVPR] Not Just Selection, but Exploration Online Class-Incremental Continual Learning via Dual View Consistency [[paper](https://ieeexplore.ieee.org/abstract/document/9879220)]

- <a name='todo'></a> [2022 CVPR] Mimicking the Oracle An Initial Phase Decorrelation Approach for Class Incremental Learning [[paper](https://arxiv.org/abs/2112.04731)]

- <a name='todo'></a> [2022 CVPR] MetaFSCIL A Meta-Learning Approach for Few-Shot Class Incremental Learning [[paper](https://ieeexplore.ieee.org/document/9878925)]

- <a name='todo'></a> [2022 CVPR] Meta-attention for ViT-backed Continual Learning [[paper](https://arxiv.org/abs/2203.11684)]

- <a name='todo'></a> [2022 CVPR] Lifelong Graph Learning [[paper](https://arxiv.org/abs/2202.10688)]

- <a name='todo'></a> [2022 CVPR] Learning to Prompt for Continual Learning [[paper](https://arxiv.org/abs/2112.08654)]

- <a name='todo'></a> [2022 CVPR] Learning to Imagine Diversify Memory for Incremental Learning using Unlabeled Data [[paper](https://arxiv.org/abs/2204.08932)]

- <a name='todo'></a> [2022 CVPR] Learning Bayesian Sparse Networks with Full Experience Replay for Continual Learning [[paper](https://arxiv.org/abs/2202.10203)]

- <a name='todo'></a> [2022 CVPR] Incremental Transformer Structure Enhanced Image Inpainting with Masking Positional Encoding [[paper](https://arxiv.org/abs/2203.00867)]

- <a name='todo'></a> [2022 CVPR] Incremental Learning in Semantic Segmentation from Image Labels [[paper](https://arxiv.org/pdf/2112.01882.pdf)]

- <a name='todo'></a> [2022 CVPR] General Incremental Learning with Domain-aware Categorical Representations [[paper](https://arxiv.org/abs/2204.04078)]

- <a name='todo'></a> [2022 CVPR] GCR GRADIENT CORESET BASED REPLAY BUFFER SELECTION FOR CONTINUAL LEARNING [[paper](https://arxiv.org/abs/2111.11210)]

- <a name='todo'></a> [2022 CVPR] Forward Compatible Few-Shot Class-Incremental Learning [[paper](https://arxiv.org/abs/2203.06953)]

- <a name='todo'></a> [2022 CVPR] Few-Shot Incremental Learning for Label-to-Image Translation [[paper](https://ieeexplore.ieee.org/document/9878463)]

- <a name='todo'></a> [2022 CVPR] Federated Class-Incremental Learning [[paper](https://arxiv.org/abs/2203.11473)]

- <a name='todo'></a> [2022 CVPR] Energy-based Latent Aligner for Incremental Learning [[paper](https://arxiv.org/abs/2203.14952)]

- <a name='todo'></a> [2022 CVPR] DyTox Transformers for Continual Learning with DYnamic TOken eXpansion [[paper](https://arxiv.org/abs/2111.11326)]

- <a name='todo'></a> [2022 CVPR] Doodle It Yourself Class Incremental Learning by Drawing a Few Sketches [[paper](https://arxiv.org/abs/2203.14843)]

- <a name='todo'></a> [2022 CVPR] Continual Learning with Lifelong Vision Transformer [[paper](https://ieeexplore.ieee.org/document/9880356)]

- <a name='todo'></a> [2022 CVPR] Continual Learning for Visual Search with Backward Consistent Feature Embedding [[paper](https://arxiv.org/abs/2205.13384)]

- <a name='todo'></a> [2022 CVPR] Constrained Few-shot Class-incremental Learning [[paper](https://arxiv.org/abs/2203.16588)]

- <a name='todo'></a> [2022 CVPR] Class-Incremental Learning with Strong Pre-trained Models [[paper](https://arxiv.org/abs/2204.03634)]

- <a name='todo'></a> [2022 CVPR] Class-Incremental Learning by Knowledge Distillation with Adaptive Feature Consolidation [[paper](https://arxiv.org/abs/2204.00895)]

- <a name='todo'></a> [2022 CVPR] Bring Evanescent Representations to Life in Lifelong Class Incremental Learning [[paper](https://ieeexplore.ieee.org/document/9878745)]

- <a name='todo'></a> [2022 CVIU] Balanced softmax cross-entropy for incremental learning with and without memory [[paper](https://arxiv.org/abs/2103.12532)]

- <a name='todo'></a> [2022 COLING] Incremental Prompting_ Episodic Memory Prompt for Lifelong Event Detection [[paper](https://arxiv.org/abs/2204.07275)]

- <a name='todo'></a> [2022 COLING] Dynamic Dialogue Policy for Continual Reinforcement Learning [[paper](https://arxiv.org/abs/2204.05928)]

- <a name='todo'></a> [2022 COLING] Continual Few-shot Intent Detection [[paper](https://aclanthology.org/2022.coling-1.26/)]

- <a name='todo'></a> [2022 ACL] Overcoming Catastrophic Forgetting beyond Continual Learning_ Balanced Training for Neural Machine Translation [[paper](https://arxiv.org/abs/2203.03910)]

- <a name='todo'></a> [2022 ACL] Few-Shot Class-Incremental Learning for Named Entity Recognition [[paper](https://aclanthology.org/2022.acl-long.43/)]

- <a name='todo'></a> [2022 ACL] Continual Sequence Generation with Adaptive Compositional Modules [[paper](https://arxiv.org/abs/2203.10652)]

- <a name='todo'></a> [2022 ACL] Continual Prompt Tuning for Dialog State Tracking [[paper](https://arxiv.org/abs/2203.06654)]

- <a name='todo'></a> [2022 ACL] Continual Pre-training of Language Models for Math Problem Understanding with Syntax-Aware Memory Network [[paper](https://aclanthology.org/2022.acl-long.408/)]

- <a name='todo'></a> [2022 ACL] Continual Few-shot Relation Learning via Embedding Space Regularization and Data Augmentation [[paper](https://arxiv.org/abs/2203.02135)]

- <a name='todo'></a> [2022 ACL] ConTinTin_ Continual Learning from Task Instructions [[paper](https://arxiv.org/abs/2203.08512)]

- <a name='todo'></a> [2022 AAAI] Static-Dynamic Co-teaching for Class-Incremental 3D Object Detection [[paper](https://arxiv.org/abs/2112.07241)]

- <a name='todo'></a> [2022 AAAI] Same State, Different Task Continual Reinforcement Learning without Interference [[paper](https://arxiv.org/abs/2106.02940)]

- <a name='todo'></a> [2022 AAAI] Learngene From Open-World to Your Learning Task [[paper](https://arxiv.org/abs/2106.06788)]

- <a name='todo'></a> [2022 AAAI] Continual Learning through Retrieval and Imagination [[paper](https://doi.org/10.1609/aaai.v36i8.20837)]

- <a name='todo'></a> [2022 AAAI] Adaptive Orthogonal Projection for Batch and Online Continual Learning [[paper](https://doi.org/10.1609/aaai.v36i6.20634)]

### 2021

- <a name='todo'></a> [2021 arXiv] SPeCiaL Self-Supervised Pretraining for Continual Learning [[paper](https://arxiv.org/abs/2106.09065)]

- <a name='todo'></a> [2021 arXiv] An Empirical Investigation of the Role of Pre-training in Lifelong Learning [[paper](https://arxiv.org/abs/2112.09153)]

- <a name='todo'></a> [2021 WACV] Do not Forget to Attend to Uncertainty while Mitigating Catastrophic Forgetting [[paper](https://arxiv.org/abs/2102.01906)]

- <a name='todo'></a> [2021 TPAMI] Incremental Object Detection via Meta-Learning [[paper](https://arxiv.org/abs/2003.08798)]

- <a name='todo'></a> [2021 TNNLS] Triple-Memory Networks A Brain-Inspired Method for Continual Learning [[paper](https://arxiv.org/abs/2003.03143)]

- <a name='todo'></a> [2021 PRL] ACAE-REMIND for Online Continual Learning with Compressed Feature Replay [[paper](https://arxiv.org/abs/2105.08595)]

- <a name='todo'></a> [2021 NeurIPS] SSUL Semantic Segmentation with Unknown Label for Exemplar-based Class-Incremental Learning [[paper](https://arxiv.org/abs/2106.11562)]

- <a name='todo'></a> [2021 NeurIPS] RMM Reinforced Memory Management for Class-Incremental Learning [[paper](https://arxiv.org/abs/2301.05792)]

- <a name='todo'></a> [2021 NeurIPS] Posterior Meta-Replay for Continual Learning [[paper](https://arxiv.org/abs/2103.01133)]

- <a name='todo'></a> [2021 NeurIPS] Overcoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima [[paper](https://arxiv.org/abs/2111.01549)]

- <a name='todo'></a> [2021 NeurIPS] Optimizing Reusable Knowledge for Continual Learning via Metalearning [[paper](https://arxiv.org/abs/2106.05390)]

- <a name='todo'></a> [2021 NeurIPS] Natural continual learning success is a journey, not (just) a destination [[paper](https://arxiv.org/abs/2106.08085)]

- <a name='todo'></a> [2021 NeurIPS] Mitigating Forgetting in Online Continual Learning with Neuron Calibration [[paper](https://arxiv.org/abs/2211.05347)]

- <a name='todo'></a> [2021 NeurIPS] Lifelong Domain Adaptation via Consolidated Internal Distribution [[paper](https://openreview.net/forum?id=lpW-UP8VKcg)]

- <a name='todo'></a> [2021 NeurIPS] Learning where to learn Gradient sparsity in meta and continual learning [[paper](https://arxiv.org/abs/2110.14402)]

- <a name='todo'></a> [2021 NeurIPS] Gradient-based Editing of Memory Examples for Online Task-free Continual Learning [[paper](https://arxiv.org/abs/2006.15294)]

- <a name='todo'></a> [2021 NeurIPS] Generative vs Discriminative Rethinking The Meta-Continual Learning [[paper](https://openreview.net/forum?id=soDi-HkzC1)]

- <a name='todo'></a> [2021 NeurIPS] Formalizing the Generalization-Forgetting Trade-Off in Continual Learning [[paper](https://arxiv.org/abs/2109.14035)]

- <a name='todo'></a> [2021 NeurIPS] Flattening Sharpness for Dynamic Gradient Projection Memory Benefits Continual Learning [[paper](https://arxiv.org/abs/2110.04593)]

- <a name='todo'></a> [2021 NeurIPS] DualNet Continual Learning, Fast and Slow [[paper](https://arxiv.org/abs/2110.00175)]

- <a name='todo'></a> [2021 NeurIPS] Continual World_ A Robotic Benchmark For Continual Reinforcement Learning [[paper](https://arxiv.org/abs/2105.10919)]

- <a name='todo'></a> [2021 NeurIPS] Continual Learning via Local Module Composition [[paper](https://arxiv.org/abs/2111.07736)]

- <a name='todo'></a> [2021 NeurIPS] Continual Auxiliary Task Learning [[paper](https://arxiv.org/abs/2202.11133)]

- <a name='todo'></a> [2021 NeurIPS] Class-Incremental Learning via Dual Augmentation [[paper](https://openreview.net/forum?id=8dqEeFuhgMG)]

- <a name='todo'></a> [2021 NeurIPS] Bridging Non Co-occurrence with Unlabeled In-the-wild Data for Incremental Object Detection [[paper](https://arxiv.org/abs/2110.15017)]

- <a name='todo'></a> [2021 NeurIPS] BooVAE Boosting Approach for Continual Learning of VAE [[paper](https://arxiv.org/abs/1908.11853)]

- <a name='todo'></a> [2021 NeurIPS] BNS Building Network Structures Dynamically for Continual Learning [[paper](https://openreview.net/forum?id=2ybxtABV2Og)]

- <a name='todo'></a> [2021 NeurIPS] AFEC Active Forgetting of Negative Transfer in Continual Learning [[paper](https://arxiv.org/abs/2110.12187)]

- <a name='todo'></a> [2021 NeurIPS] Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning [[paper](https://arxiv.org/abs/2112.02706)]

- <a name='todo'></a> [2021 NAACL] Towards Continual Learning for Multilingual Machine Translation via Vocabulary Substitution [[paper](https://arxiv.org/abs/2103.06799)]

- <a name='todo'></a> [2021 NAACL] Continual Learning for Text Classification with Information Disentanglement Based Regularization [[paper](https://arxiv.org/abs/2104.05489v1)]

- <a name='todo'></a> [2021 NAACL] Continual Learning for Neural Machine Translation [[paper](https://aclanthology.org/2021.naacl-main.310/)]

- <a name='todo'></a> [2021 NAACL] Adapting BERT for Continual Learning of a Sequence of Aspect Sentiment Classification Tasks [[paper](https://arxiv.org/abs/2112.03271)]

- <a name='todo'></a> [2021 MM] Video Transformer for Deepfake Detection with Incremental Learning [[paper](https://arxiv.org/abs/2108.05307)]

- <a name='todo'></a> [2021 MM] Remember and Reuse_ Cross-Task Blind Image Quality Assessment via Relevance-aware Incremental Learning [[paper](https://doi.org/10.1145/3474085.3475642)]

- <a name='todo'></a> [2021 MM] Co-Transport for Class-Incremental Learning [[paper](https://arxiv.org/abs/2107.12654)]

- <a name='todo'></a> [2021 MM] An EM Framework for Online Incremental Learning of Semantic Segmentation [[paper](https://arxiv.org/abs/2108.03613)]

- <a name='todo'></a> [2021 IJCAI] TrafficStream_ A Streaming Traffic Flow Forecasting Framework Based on Graph Neural Networks and Continual Learning [[paper](https://arxiv.org/abs/2106.06273)]

- <a name='todo'></a> [2021 IJCAI] Learning with Selective Forgetting [[paper](https://doi.org/10.24963/ijcai.2021/137)]

- <a name='todo'></a> [2021 IJCAI] Knowledge Consolidation based Class Incremental Online Learning with Limited Data [[paper](https://arxiv.org/abs/2106.06795)]

- <a name='todo'></a> [2021 IJCAI] FedSpeech_ Federated Text-to-Speech with Continual Learning [[paper](https://arxiv.org/abs/2110.07216)]

- <a name='todo'></a> [2021 ICPR] Semi-Supervised Class Incremental Learning [[paper](https://ieeexplore.ieee.org/abstract/document/9413225)]

- <a name='todo'></a> [2021 ICPR] Class-incremental Learning with Pre-allocated Fixed Classifiers [[paper](https://arxiv.org/abs/2010.08657)]

- <a name='todo'></a> [2021 ICML] Variational Auto-Regressive Gaussian Processes for Continual Learning [[paper](https://arxiv.org/abs/2006.05468)]

- <a name='todo'></a> [2021 ICML] Kernel Continual Learning [[paper](https://arxiv.org/abs/2107.05757)]

- <a name='todo'></a> [2021 ICML] GP-Tree A Gaussian Process Classifier for Few-Shot Incremental Learning [[paper](https://arxiv.org/abs/2102.07868)]

- <a name='todo'></a> [2021 ICML] Federated Continual Learning with Weighted Inter-client Transfer [[paper](https://arxiv.org/abs/2003.03196)]

- <a name='todo'></a> [2021 ICML] Continuous Coordination As a Realistic Scenario for Lifelong Learning [[paper](https://arxiv.org/abs/2103.03216)]

- <a name='todo'></a> [2021 ICML] Continual Learning in the Teacher-Student Setup Impact of Task Similarity [[paper](https://arxiv.org/pdf/2107.04384.pdf)]

- <a name='todo'></a> [2021 ICML] Bayesian Structural Adaptation for Continual Learning [[paper](https://arxiv.org/abs/1912.03624)]

- <a name='todo'></a> [2021 ICLR] Remembering for the Right Reasons: Explanations Reduce Catastrophic Forgetting [[paper](https://openreview.net/pdf?id=tHgJoMfy6nI)]

- <a name='todo'></a> [2021 ICLR] Linear Mode Connectivity in Multitask and Continual Learning [[paper](https://arxiv.org/abs/2010.04495)]

- <a name='todo'></a> [2021 ICLR] Gradient Projection Memory for Continual Learning [[paper](https://arxiv.org/abs/2103.09762)]

- <a name='todo'></a> [2021 ICLR] Generalized Variational Continual Learning [[paper](https://openreview.net/forum?id=_IM-AfFhna9)]

- <a name='todo'></a> [2021 ICLR] Efficient Continual Learning with Modular Networks and Task-Driven Priors [[paper](https://openreview.net/forum?id=EKV158tSfwv)]

- <a name='todo'></a> [2021 ICLR] EEC: Learning to Encode and Regenerate Images for Continual Learning [[paper](https://arxiv.org/abs/2101.04904)]

- <a name='todo'></a> [2021 ICLR] CPR: Classifier-Projection Regularization for Continual Learning [[paper](https://openreview.net/forum?id=F2v4aqEL6ze)]

- <a name='todo'></a> [2021 ICLR] Continual Learning in Recurrent Neural Networks [[paper](https://openreview.net/forum?id=8xeBUgD8u9)]

- <a name='todo'></a> [2021 ICLR] Contextual Transformation Networks for Online Continual Learning [[paper](https://openreview.net/forum?id=zx_uX-BO7CH)]

- <a name='todo'></a> [2021 ICCV] Wanderlust Online Continual Object Detection in the Real World [[paper](https://arxiv.org/abs/2108.11005)]

- <a name='todo'></a> [2021 ICCV] Synthesized Feature based Few-Shot Class-Incremental Learning on a Mixture of Subspaces [[paper](https://ieeexplore.ieee.org/document/9711372)]

- <a name='todo'></a> [2021 ICCV] Striking a Balance between Stability and Plasticity for Class-Incremental Learning [[paper](https://ieeexplore.ieee.org/document/9711484)]

- <a name='todo'></a> [2021 ICCV] SS-IL Separated Softmax for Incremental Learning [[paper](https://ieeexplore.ieee.org/document/9710553)]

- <a name='todo'></a> [2021 ICCV] Rehearsal revealed The limits and merits of revisiting samples in continual learning [[paper](https://arxiv.org/abs/2104.07446)]

- <a name='todo'></a> [2021 ICCV] RECALL Replay-based Continual Learning in Semantic Segmentation [[paper](https://arxiv.org/abs/2108.03673)]

- <a name='todo'></a> [2021 ICCV] Online Continual Learning with Natural Distribution Shifts An Empirical Study with Visual Data [[paper](https://arxiv.org/abs/2108.09020)]

- <a name='todo'></a> [2021 ICCV] Generalized and Incremental Few-Shot Learning by Explicit Learning and Calibration without Forgetting [[paper](https://arxiv.org/abs/2108.08165)]

- <a name='todo'></a> [2021 ICCV] Few-Shot and Continual Learning with Attentive Independent Mechanisms [[paper](https://arxiv.org/abs/2107.14053)]

- <a name='todo'></a> [2021 ICCV] Else-Net: Elastic Semantic Network for Continual Action Recognition from Skeleton Data [[paper](https://ieeexplore.ieee.org/document/9711342)]

- <a name='todo'></a> [2021 ICCV] Detection and Continual Learning of Novel Face Presentation Attacks [[paper](https://arxiv.org/abs/2108.12081)]

- <a name='todo'></a> [2021 ICCV] Continual Prototype Evolution Learning Online from Non-Stationary Data Streams [[paper](https://arxiv.org/abs/2009.00919)]

- <a name='todo'></a> [2021 ICCV] Continual Learning on Noisy Data Streams via Self-Purified Replay [[paper](https://arxiv.org/abs/2110.07735)]

- <a name='todo'></a> [2021 ICCV] Continual Learning for Image-Based Camera Localization [[paper](https://arxiv.org/abs/2108.09112)]

- <a name='todo'></a> [2021 ICCV] Co2L Contrastive Continual Learning [[paper](https://arxiv.org/abs/2106.14413)]

- <a name='todo'></a> [2021 ICCV] Class-Incremental Learning for Action Recognition in Videos [[paper](https://arxiv.org/abs/2203.13611)]

- <a name='todo'></a> [2021 ICCV] Always Be Dreaming A New Approach for Data-Free Class-Incremental Learning [[paper](https://arxiv.org/abs/2106.09701)]

- <a name='todo'></a> [2021 EMNLP] Total Recall_ a Customized Continual Learning Method for Neural Semantic Parsers [[paper](https://arxiv.org/abs/2109.05186)]

- <a name='todo'></a> [2021 EMNLP] ECONET_ Effective Continual Pretraining of Language Models for Event Temporal Reasoning [[paper](https://arxiv.org/abs/2012.15283)]

- <a name='todo'></a> [2021 EMNLP] Continual Learning in Task-Oriented Dialogue Systems [[paper](https://arxiv.org/abs/2012.15504)]

- <a name='todo'></a> [2021 EMNLP] Continual Few-Shot Learning for Text Classification [[paper](https://aclanthology.org/2021.emnlp-main.460/)]

- <a name='todo'></a> [2021 EMNLP] CLASSIC Continual and Contrastive Learning of Aspect Sentiment Classification Tasks [[paper](https://arxiv.org/abs/2112.02714)]

- <a name='todo'></a> [2021 CVPR] Training Networks in Null Space of Feature Covariance for Continual Learning [[paper](https://arxiv.org/abs/2103.07113)]

- <a name='todo'></a> [2021 CVPR] Towards Open World Object Detection [[paper](https://arxiv.org/abs/2103.02603)]

- <a name='todo'></a> [2021 CVPR] Semantic-aware Knowledge Distillation for Few-Shot Class-Incremental Learning [[paper](https://arxiv.org/abs/2103.04059)]

- <a name='todo'></a> [2021 CVPR] Self-Promoted Prototype Refinement for Few-Shot Class-Incremental Learning [[paper](https://arxiv.org/abs/2107.08918)]

- <a name='todo'></a> [2021 CVPR] Rectification-based Knowledge Retention for Continual Learning [[paper](None)]

- <a name='todo'></a> [2021 CVPR] Rainbow Memory Continual Learning with a Memory of Diverse Samples [[paper](https://arxiv.org/abs/2103.17230)]

- <a name='todo'></a> [2021 CVPR] Prototype Augmentation and Self-Supervision for Incremental Learning [[paper](https://ieeexplore.ieee.org/document/9578909)]

- <a name='todo'></a> [2021 CVPR] PLOP Learning without Forgetting for Continual Semantic Segmentation [[paper](https://arxiv.org/abs/2011.11390)]

- <a name='todo'></a> [2021 CVPR] ORDisCo Effective and Efficient Usage of Incremental Unlabeled Data for Semi-supervised Continual Learning [[paper](https://arxiv.org/abs/2101.00407)]

- <a name='todo'></a> [2021 CVPR] On Learning the Geodesic Path for Incremental Learning [[paper](https://arxiv.org/abs/2104.08572)]

- <a name='todo'></a> [2021 CVPR] Lifelong Person Re-Identification via Adaptive Knowledge Accumulation [[paper](https://arxiv.org/abs/2103.12462)]

- <a name='todo'></a> [2021 CVPR] Layerwise Optimization by Gradient Decomposition for Continual Learning [[paper](https://arxiv.org/abs/2105.07561)]

- <a name='todo'></a> [2021 CVPR] Incremental Learning via Rate Reduction [[paper](https://arxiv.org/abs/2011.14593)]

- <a name='todo'></a> [2021 CVPR] Incremental Few-Shot Instance Segmentation [[paper](https://arxiv.org/abs/2105.05312)]

- <a name='todo'></a> [2021 CVPR] Image De-raining via Continual Learning [[paper](https://ieeexplore.ieee.org/document/9577362/)]

- <a name='todo'></a> [2021 CVPR] IIRC Incremental Implicitly-Refined Classification [[paper](https://arxiv.org/abs/2012.12477)]

- <a name='todo'></a> [2021 CVPR] Hyper-LifelongGAN Scalable Lifelong Learning for Image Conditioned Generation [[paper](https://ieeexplore.ieee.org/document/9578318)]

- <a name='todo'></a> [2021 CVPR] Few-Shot Incremental Learning with Continually Evolved Classifiers [[paper](https://arxiv.org/abs/2104.03047)]

- <a name='todo'></a> [2021 CVPR] Efficient Feature Transformations for Discriminative and Generative Continual Learning [[paper](https://arxiv.org/abs/2103.13558)]

- <a name='todo'></a> [2021 CVPR] Distilling Causal Effect of Data in Class-Incremental Learning [[paper](https://ieeexplore.ieee.org/document/9578597)]

- <a name='todo'></a> [2021 CVPR] DER Dynamically Expandable Representation for Class Incremental Learning [[paper](https://arxiv.org/abs/2103.16788)]

- <a name='todo'></a> [2021 CVPR] Continual Semantic Segmentation via Repulsion-Attraction of Sparse and Disentangled Latent Representations [[paper](https://arxiv.org/abs/2103.06342)]

- <a name='todo'></a> [2021 CVPR] Continual Learning via Bit-Level Information Preserving [[paper](https://arxiv.org/abs/2105.04444v1)]

- <a name='todo'></a> [2021 CVPR] Continual Adaptation of Visual Representations via Domain Randomization and Meta-learning [[paper](https://ieeexplore.ieee.org/document/9578295/)]

- <a name='todo'></a> [2021 CVPR] Adaptive Aggregation Networks for Class-Incremental Learning [[paper](https://arxiv.org/abs/2010.05063)]

- <a name='todo'></a> [2021 CVIU] SID Incremental Learning for Anchor-Free Object Detection via Selective and Inter-Related Distillation [[paper](https://arxiv.org/abs/2012.15439)]

- <a name='todo'></a> [2021 CVIU] Knowledge Distillation for Incremental Learning in Semantic Segmentation [[paper](https://arxiv.org/abs/1911.03462)]

- <a name='todo'></a> [2021 BMVC] Self-Supervised Training Enhances Online Continual Learning [[paper](https://arxiv.org/abs/2103.14010)]

- <a name='todo'></a> [2021 AISTATS] Continual Learning using a Bayesian Nonparametric Dictionary of Weight Factors  [[paper](https://arxiv.org/abs/2004.10098)]

- <a name='todo'></a> [2021 AISTATS] A Theoretical Analysis of Catastrophic Forgetting through the NTK Overlap Matrix [[paper](https://arxiv.org/abs/2010.04003)]

- <a name='todo'></a> [2021 AAAI] Using Hindsight to Anchor Past Knowledge in Continual Learning [[paper](https://arxiv.org/abs/2002.08165)]

- <a name='todo'></a> [2021 AAAI] Unsupervised Model Adaptation for Continual Semantic Segmentation [[paper](https://arxiv.org/pdf/2009.12518v1.pdf)]

- <a name='todo'></a> [2021 AAAI] Split-and-Bridge Adaptable Class Incremental Learning within a Single Neural Network [[paper](https://arxiv.org/abs/2107.01349)]

- <a name='todo'></a> [2021 AAAI] Online Class-Incremental Continual Learning with Adversarial Shapley Value [[paper](https://arxiv.org/abs/2009.00093)]

- <a name='todo'></a> [2021 AAAI] Lifelong and Continual Learning Dialogue Systems Learning during Conversation [[paper](https://arxiv.org/abs/2211.06553)]

- <a name='todo'></a> [2021 AAAI] Gradient Regularized Contrastive Learning for Continual Domain Adaptation [[paper](https://arxiv.org/abs/2103.12294v1)]

- <a name='todo'></a> [2021 AAAI] Few-Shot Lifelong Learning [[paper](https://arxiv.org/abs/2103.00991)]

- <a name='todo'></a> [2021 AAAI] Few-Shot Class-Incremental Learning via Relation Knowledge Distillation [[paper](https://doi.org/10.1609/aaai.v35i2.16213)]

- <a name='todo'></a> [2021 AAAI] Curriculum-Meta Learning for Order-Robust Continual Relation Extraction [[paper](https://arxiv.org/abs/2101.01926)]

- <a name='todo'></a> [2021 AAAI] Continual Learning for Named Entity Recognition [[paper](https://aclanthology.org/2022.findings-acl.179.pdf)]

- <a name='todo'></a> [2021 AAAI] Continual Learning by Using Information of Each Class Holistically [[paper](https://doi.org/10.1609/aaai.v35i9.16952)]

- <a name='todo'></a> [2021 AAAI] Class-Incremental Instance Segmentation via Multi-Teacher Networks [[paper](https://doi.org/10.1609/aaai.v35i2.16238)]

- <a name='todo'></a> [2021 AAAI] A Continual Learning Framework for Uncertainty-Aware Interactive Image Segmentation [[paper](https://doi.org/10.1609/aaai.v35i7.16752)]

- <a name='todo'></a> [2020 WACV] ScaIL Classifier Weights Scaling for Class Incremental Learning [[paper](https://ieeexplore.ieee.org/document/9093562/)]

### 2020

- <a name='todo'></a> [2020 WACV] Class-incremental Learning via Deep Model Consolidation [[paper](https://arxiv.org/abs/1903.07864)]

- <a name='todo'></a> [2020 TPAMI] RPSNet An Adaptive Random Path Selection Approach for Incremental Learning [[paper](https://arxiv.org/abs/1906.01120)]

- <a name='todo'></a> [2020 TPAMI] Continual Learning Using Bayesian Neural Networks [[paper](https://arxiv.org/abs/1910.04112)]

- <a name='todo'></a> [2020 PRL] Faster ILOD Incremental Learning for Object Detectors based on Faster RCNN [[paper](https://arxiv.org/abs/2003.03901)]

- <a name='todo'></a> [2020 NeurIPS] Understanding the Role of Training Regimes in Continual Learning [[paper](https://arxiv.org/abs/2006.06958)]

- <a name='todo'></a> [2020 NeurIPS] RATT Recurrent Attention to Transient Tasks for Continual Image Captioning [[paper](https://openreview.net/forum?id=DlhyudbShm)]

- <a name='todo'></a> [2020 NeurIPS] Organizing recurrent network dynamics by task-computation to enable continual learning [[paper](https://dl.acm.org/doi/10.5555/3495724.3496930)]

- <a name='todo'></a> [2020 NeurIPS] Online Fast Adaptation and Knowledge Accumulation (OSAKA) a New Approach to Continual Learning [[paper](https://arxiv.org/abs/2003.05856)]

- <a name='todo'></a> [2020 NeurIPS] Mitigating Forgetting in Online Continual Learning via Instance-Aware Parameterization [[paper](https://dl.acm.org/doi/abs/10.5555/3495724.3497189)]

- <a name='todo'></a> [2020 NeurIPS] Meta-Consolidation for Continual Learning [[paper](https://arxiv.org/abs/2010.00352)]

- <a name='todo'></a> [2020 NeurIPS] Lifelong Policy Gradient Learning of Factored Policies for Faster Training Without Forgetting [[paper](https://arxiv.org/abs/2007.07011)]

- <a name='todo'></a> [2020 NeurIPS] La-MAML_ Look-ahead Meta Learning for Continual Learning [[paper](https://arxiv.org/abs/2007.13904)]

- <a name='todo'></a> [2020 NeurIPS] GAN Memory with No Forgetting [[paper](https://arxiv.org/abs/2006.07543)]

- <a name='todo'></a> [2020 NeurIPS] Dark Experience for General Continual Learning a Strong, Simple Baseline [[paper](https://arxiv.org/abs/2004.07211)]

- <a name='todo'></a> [2020 NeurIPS] Coresets via Bilevel Optimization for Continual Learning and Streaming [[paper](https://arxiv.org/abs/2006.03875)]

- <a name='todo'></a> [2020 NeurIPS] Continual Learning with Node-Importance based Adaptive Group Sparse Regularization [[paper](https://arxiv.org/abs/2003.13726)]

- <a name='todo'></a> [2020 NeurIPS] Continual Learning of Control Primitives Skill Discovery via Reset-Games [[paper](https://arxiv.org/abs/2011.05286)]

- <a name='todo'></a> [2020 NeurIPS] Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks [[paper](https://arxiv.org/abs/2112.10017)]

- <a name='todo'></a> [2020 NeurIPS] Continual Learning in Low-rank Orthogonal Subspaces [[paper](https://arxiv.org/abs/2010.11635)]

- <a name='todo'></a> [2020 NeurIPS] Continual Deep Learning by Functional Regularisation of Memorable Past [[paper](https://openreview.net/pdf?id=ib_vapuIazp)]

- <a name='todo'></a> [2020 NeurIPS] Calibrating CNNs for Lifelong Learning [[paper](https://dl.acm.org/doi/abs/10.5555/3495724.3497031)]

- <a name='todo'></a> [2020 Nat Comm] Brain-inspired replay for continual learning with artificial neural networks [[paper](https://www.nature.com/articles/s41467-020-17866-2)]

- <a name='todo'></a> [2020 IJCNN] OvA-INN Continual Learning with Invertible Neural Networks [[paper](https://ieeexplore.ieee.org/document/9206766/)]

- <a name='todo'></a> [2020 ICML] XtarNet Learning to Extract Task-Adaptive Representation for Incremental Few-Shot Learning [[paper](https://arxiv.org/abs/2003.08561)]

- <a name='todo'></a> [2020 ICML] Optimal Continual Learning has Perfect Memory and is NP-HARD [[paper](https://arxiv.org/abs/2006.05188)]

- <a name='todo'></a> [2020 ICML] Online Learned Continual Compression with Adaptive Quantization Modules [[paper](https://arxiv.org/abs/1911.08019)]

- <a name='todo'></a> [2020 ICML] Online Continual Learning from Imbalanced Data [[paper](https://dl.acm.org/doi/10.5555/3524938.3525120)]

- <a name='todo'></a> [2020 ICML] Neural Topic Modeling with Continual Lifelong Learning [[paper](https://arxiv.org/abs/2006.10909)]

- <a name='todo'></a> [2020 ICMLW] Wandering Within a World Online Contextualized Few-Shot Learning [[paper](https://openreview.net/pdf/798a88cd0aefedd9aab888bc91f17fb86841e232.pdf)]

- <a name='todo'></a> [2020 ICML] XtarNet Learning to Extract Task-Adaptive Representation for Incremental Few-Shot Learning [[paper](https://arxiv.org/abs/2003.08561)]

- <a name='todo'></a> [2020 ICML] Optimal Continual Learning has Perfect Memory and is NP-HARD [[paper](https://arxiv.org/abs/2006.05188)]

- <a name='todo'></a> [2020 ICML] Online Learned Continual Compression with Adaptive Quantization Modules [[paper](https://arxiv.org/abs/1911.08019)]

- <a name='todo'></a> [2020 ICML] Online Continual Learning from Imbalanced Data [[paper](https://dl.acm.org/doi/10.5555/3524938.3525120)]

- <a name='todo'></a> [2020 ICML] Neural Topic Modeling with Continual Lifelong Learning [[paper](https://arxiv.org/abs/2006.10909)]

- <a name='todo'></a> [2020 ICMLW] Variational Beam Search for Continual Learning [[zoom](https://icml.cc/virtual/2020/8260)]

- <a name='todo'></a> [2020 ICMLW] Variational Auto-Regressive Gaussian Processes for Continual Learning [[paper](https://arxiv.org/abs/2006.05468)]

- <a name='todo'></a> [2020 ICMLW] Understanding Regularisation Methods for Continual Learning [[paper](https://arxiv.org/abs/2006.06357v1)]

- <a name='todo'></a> [2020 ICMLW] UNCLEAR: A Straightforward Method for Continual Reinforcement Learning [[paper](https://www.oxford-man.ox.ac.uk/wp-content/uploads/2020/11/UNCLEAR-A-Straightforward-Method-for-Continual-Reinforcement-Learning.pdf)]

- <a name='todo'></a> [2020 ICMLW] Task-Agnostic Continual Learning via Stochastic Synapses [[zoom](https://icml.cc/virtual/2020/8253)]

- <a name='todo'></a> [2020 ICMLW] Supermasks in Superposition [[paper](https://arxiv.org/abs/2006.14769)]

- <a name='todo'></a> [2020 ICMLW] SOLA Continual Learning with Second-Order Loss Approximation [[paper](https://arxiv.org/abs/2006.10974)]

- <a name='todo'></a> [2020 ICMLW] Routing Networks with Co-training for Continual Learning [[paper](https://arxiv.org/abs/2009.04381)]

- <a name='todo'></a> [2020 ICMLW] On Class Orderings for Incremental Learning [[paper](https://arxiv.org/abs/2007.02145)]

- <a name='todo'></a> [2020 ICMLW] Deep Reinforcement Learning amidst Lifelong Non-Stationarity [[paper](https://openreview.net/pdf?id=P1OwHAhDVbd)]

- <a name='todo'></a> [2020 ICMLW] Continual Reinforcement Learning with Multi-Timescale Replay [[paper](https://arxiv.org/abs/2004.07530)]

- <a name='todo'></a> [2020 ICMLW] Continual Learning in Human Activity Recognition: an Empirical Analysis of Regularization [[paper](https://arxiv.org/abs/2007.03032)]

- <a name='todo'></a> [2020 ICMLW] Continual Learning from the Perspective of Compression [[paper](https://arxiv.org/abs/2006.15078)]

- <a name='todo'></a> [2020 ICMLW] Combining Variational Continual Learning with FiLM Layers [[paper](https://openreview.net/forum?id=fZBEGA1d-4Y)]

- <a name='todo'></a> [2020 ICMLW] Anatomy of Catastrophic Forgetting Hidden Representations and Task Semantics [[paper](https://openreview.net/forum?id=LhY8QdUGSuw)]

- <a name='todo'></a> [2020 ICMLW] A General Framework for Continual Learning of Compositional Structures [[paper](https://www.cis.upenn.edu/~eeaton/papers/Mendez2020General.pdf)]

- <a name='todo'></a> [2020 ICLR] UNCERTAINTY-GUIDED CONTINUAL LEARNING WITH BAYESIAN NEURAL NETWORKS [[paper](https://openreview.net/pdf?id=HklUCCVKDB)]

- <a name='todo'></a> [2020 ICLR] SCALABLE AND ORDER-ROBUST CONTINUAL LEARNING WITH ADDITIVE PARAMETER DECOMPOSITION [[paper](https://arxiv.org/abs/1902.09432)]

- <a name='todo'></a> [2020 ICLR] FUNCTIONAL REGULARISATION FOR CONTINUAL LEARNING WITH GAUSSIAN PROCESSES [[paper](https://arxiv.org/abs/1901.11356)]

- <a name='todo'></a> [2020 ICLR] CONTINUAL LEARNING WITH HYPERNETWORKS [[paper](https://openreview.net/pdf?id=SJgwNerKvB)]

- <a name='todo'></a> [2020 ICLR] CONTINUAL LEARNING WITH BAYESIAN NEURAL NETWORKS FOR NON-STATIONARY DATA [[paper](https://openreview.net/forum?id=SJlsFpVtDB)]

- <a name='todo'></a> [2020 ICLR] CONTINUAL LEARNING WITH ADAPTIVE WEIGHTS (CLAW) [[paper](https://arxiv.org/abs/1911.09514)]

- <a name='todo'></a> [2020 ICLR] COMPOSITIONAL LANGUAGE CONTINUAL LEARNING [[paper](https://openreview.net/pdf?id=rklnDgHtDS)]

- <a name='todo'></a> [2020 ICLR] A NEURAL DIRICHLET PROCESS MIXTURE MODEL FOR TASK-FREE CONTINUAL LEARNING [[paper](https://arxiv.org/abs/2001.00689)]

- <a name='todo'></a> [2020 EMNLP] Visually Grounded Continual Learning of Compositional Phrases [[paper](https://aclanthology.org/2020.emnlp-main.158/)]

- <a name='todo'></a> [2020 EMNLP] Disentangle-based Continual Graph Representation Learning [[paper](https://aclanthology.org/2020.emnlp-main.237/)]

- <a name='todo'></a> [2020 EMNLP] Continual Learning for Natural Language Generation in Task-oriented Dialog Systems [[paper](https://aclanthology.org/2020.findings-emnlp.310/)]

- <a name='todo'></a> [2020 ECCV] Topology-Preserving Class-Incremental Learning [[paper](oi.org/10.1007/978-3-030-58529-7_16)]

- <a name='todo'></a> [2020 ECCV] Side-Tuning: A Baseline for Network Adaptation via Additive Side Networks [[paper](https://arxiv.org/abs/1912.13503)]

- <a name='todo'></a> [2020 ECCV] Reparameterizing Convolutions for Incremental Multi-Task Learning without Task Interference [[paper](https://arxiv.org/abs/2007.12540)]

- <a name='todo'></a> [2020 ECCV] REMIND Your Neural Network to Prevent Catastrophic Forgetting [[paper](https://arxiv.org/abs/1910.02509)]

- <a name='todo'></a> [2020 ECCV] PODNet Pooled Outputs Distillation for Small-Tasks Incremental Learning [[paper](https://arxiv.org/abs/2004.13513)]

- <a name='todo'></a> [2020 ECCV] Piggyback GAN Efficient Lifelong Learning for Image Conditioned Generation [[paper](https://arxiv.org/abs/2104.11939)]

- <a name='todo'></a> [2020 ECCV] Online Continual Learning under Extreme Memory Constraints [[paper](https://arxiv.org/abs/2008.01510)]

- <a name='todo'></a> [2020 ECCV] More Classifiers, Less Forgetting A Generic Multi-classifier Paradigm for Incremental Learning [[paper](https://doi.org/10.1007/978-3-030-58574-7_42)]

- <a name='todo'></a> [2020 ECCV] Memory-Efficient Incremental Learning Through Feature Adaptation [[paper](https://arxiv.org/abs/2004.00713)]

- <a name='todo'></a> [2020 ECCV] Learning latent representations across multiple data domains using Lifelong VAEGAN [[paper](https://arxiv.org/abs/2007.10221)]

- <a name='todo'></a> [2020 ECCV] Incremental Meta-Learning via Indirect Discriminant Alignment [[paper](https://arxiv.org/pdf/2002.04162.pdf)]

- <a name='todo'></a> [2020 ECCV] Imbalanced Continual Learning with Partitioning Reservoir Sampling [[paper](https://arxiv.org/abs/2009.03632)]

- <a name='todo'></a> [2020 ECCV] GDumb A Simple Approach that Questions Our Progress in Continual Learning [[paper](https://openreview.net/forum?id=zeLEHYJhHp)]

- <a name='todo'></a> [2020 ECCV] Class-Incremental Domain Adaptation [[paper](https://arxiv.org/abs/2107.11091)]

- <a name='todo'></a> [2020 ECCV] Adversarial Continual Learning [[paper](https://arxiv.org/abs/2003.09553)]

- <a name='todo'></a> [2020 ECAI] Learning to Continually Learn [[paper](https://arxiv.org/pdf/2002.09571.pdf)]

- <a name='todo'></a> [2020 CVPR] Semantic Drift Compensation for Class-Incremental Learning [[paper](https://ieeexplore.ieee.org/document/9156964/)]

- <a name='todo'></a> [2020 CVPR] Modeling the Background for Incremental Learning in Semantic Segmentation [[paper](https://arxiv.org/abs/2002.00718)]

- <a name='todo'></a> [2020 CVPR] Mnemonics Training Multi-Class Incremental Learning without Forgetting [[paper](https://openreview.net/forum?id=JSmccXnFPPF)]

- <a name='todo'></a> [2020 CVPR] Maintaining Discrimination and Fairness in Class Incremental Learning [[paper](https://ieeexplore.ieee.org/document/9156766/)]

- <a name='todo'></a> [2020 CVPR] iTAML An Incremental Task-Agnostic Meta-learning Approach [[paper](https://arxiv.org/abs/2003.11652)]

- <a name='todo'></a> [2020 CVPR] Incremental Learning In Online Scenario [[paper](https://ieeexplore.ieee.org/document/9156990/)]

- <a name='todo'></a> [2020 CVPR] Incremental Few-Shot Object Detection [[paper](https://ieeexplore.ieee.org/document/9157715/)]

- <a name='todo'></a> [2020 CVPR] Few-Shot Class-Incremental Learning [[paper](https://ieeexplore.ieee.org/document/9157521)]

- <a name='todo'></a> [2020 CVPR] Dreaming to Distill Data-free Knowledge Transfer via DeepInversion [[paper](https://arxiv.org/abs/1912.08795)]

- <a name='todo'></a> [2020 CVPR] Continual Learning with Extended Kronecker-factored Approximate Curvature [[paper](https://ieeexplore.ieee.org/document/9157569)]

- <a name='todo'></a> [2020 CVPR] Conditional Channel Gated Networks for Task-Aware Continual Learning [[paper](https://ieeexplore.ieee.org/document/9156310/)]

- <a name='todo'></a> [2020 CVPRW] What is Happening Inside a Continual Learning Model_ A Representation-Based Evaluation of Representational Forgetting [[paper](https://ieeexplore.ieee.org/document/9150688)]

- <a name='todo'></a> [2020 CVPRW] Stream-51 Streaming Classification and Novelty Detection from Videos [[paper](https://ieeexplore.ieee.org/document/9150885)]

- <a name='todo'></a> [2020 CVPRW] StackNet Stacking feature maps for Continual learning [[paper](https://ieeexplore.ieee.org/document/9150740/)]

- <a name='todo'></a> [2020 CVPRW] Relationship Matters Relation Guided Knowledge Transfer for Incremental Learning of Object Detectors [[paper](https://ieeexplore.ieee.org/document/9150833/)]

- <a name='todo'></a> [2020 CVPRW] Rehearsal-Free Continual Learning over Small Non-I.I.D. Batches [[paper](https://ieeexplore.ieee.org/document/9150818/)]

- <a name='todo'></a> [2020 CVPRW] Reducing catastrophic forgetting with learning on synthetic data [[paper](https://ieeexplore.ieee.org/document/9150615/)]

- <a name='todo'></a> [2020 CVPRW] Noise-Based Selection of Robust Inherited Model for Accurate Continual Learning [[paper](https://ieeexplore.ieee.org/abstract/document/9150982)]

- <a name='todo'></a> [2020 CVPRW] Lifelong Machine Learning with Deep Streaming Linear Discriminant Analysis [[paper](https://ieeexplore.ieee.org/document/9150601/)]

- <a name='todo'></a> [2020 CVPRW] Generative Feature Replay For Class-Incremental Learning [[paper](https://ieeexplore.ieee.org/document/9150851/)]

- <a name='todo'></a> [2020 CVPRW] Generating Accurate Pseudo Examples for Continual Learning [[paper](https://ieeexplore.ieee.org/document/9150934/)]

- <a name='todo'></a> [2020 CVPRW] Generalized Class Incremental Learning [[paper](https://ieeexplore.ieee.org/document/9150844/)]

- <a name='todo'></a> [2020 CVPRW] Dropout as an Implicit Gating Mechanism For Continual Learning [[paper](https://arxiv.org/abs/2004.11545)]

- <a name='todo'></a> [2020 CVPRW] Continual Reinforcement Learning in 3D Non-stationary Environments [[paper](None)]

- <a name='todo'></a> [2020 CVPRW] Continual Learning of Object Instances [[paper](None)]

- <a name='todo'></a> [2020 CVPRW] Continual Learning for Anomaly Detection in Surveillance Videos [[paper](None)]

- <a name='todo'></a> [2020 CVPRW] Cognitively-Inspired Model for Incremental Learning Using a Few Examples [[paper](https://ieeexplore.ieee.org/document/9150667/)]

- <a name='todo'></a> [2020 CVPRW] CatNet Class Incremental 3D ConvNets for Lifelong Egocentric Gesture Recognition [[paper](None)]

- <a name='todo'></a> [2020 COLING] Investigating Catastrophic Forgetting During Continual Training for Neural Machine Translation [[paper](https://aclanthology.org/2020.coling-main.381/)]

- <a name='todo'></a> [2020 COLING] Distill and Replay for Continual Language Learning [[paper](https://aclanthology.org/2020.coling-main.318/)]

- <a name='todo'></a> [2020 COLING] Continual Lifelong Learning in Natural Language Processing_ A Survey [[paper](https://aclanthology.org/2020.coling-main.574/)]

- <a name='todo'></a> [2020 COLING] A Two-phase Prototypical Network Model for Incremental Few-shot Relation Classification [[paper](None)]

- <a name='todo'></a> [2020 BMVC] Initial Classifier Weights Replay for Memoryless Class Incremental Learning [[paper](https://arxiv.org/abs/2008.13710)]

- <a name='todo'></a> [2020 AISTATS] Orthogonal Gradient Descent for Continual Learning [[paper](https://arxiv.org/abs/1910.07104)]

- <a name='todo'></a> [2020 ACL] Continual Relation Learning via Episodic Memory Activation and Reconsolidation [[paper](https://aclanthology.org/2020.acl-main.573/)]

- <a name='todo'></a> [2020 AAAI] Residual Continual Learning [[paper](https://arxiv.org/abs/2002.06774)]

- <a name='todo'></a> [2020 AAAI] Overcoming Catastrophic Forgetting by Neuron-Level Plasticity Control [[paper](https://arxiv.org/pdf/1907.13322)]

- <a name='todo'></a> [2020 AAAI] Learning from the Past_ Continual Meta-Learning with Bayesian Graph Neural Networks [[paper](None)]

- <a name='todo'></a> [2020 AAAI] Generative Continual Concept Learning [[paper](https://arxiv.org/abs/1906.03744)]

- <a name='todo'></a> [2020 AAAI] ERNIE 2.0_ A Continual Pre-Training Framework for Language Understanding [[paper](None)]

- <a name='todo'></a> [2020 AAAI] Bi-Objective Continual Learning_ Learning ‘New’ While Consolidating ‘Known’ [[paper](None)]

### 2019

- <a name='todo'></a> [2019 NIPS] Uncertainty-based Continual Learning with Adaptive Regularization [[paper](https://arxiv.org/abs/1905.11614)]

- <a name='todo'></a> [2019 NIPS] RPSNet Random Path Selection for Incremental Learning [[paper](None)]
 
- <a name='todo'></a> [2019 NIPS] Reconciling meta-learning and continual learning with online mixtures of tasks [[paper](None)]

### 2019

### 2018

### 2017

### 2016

