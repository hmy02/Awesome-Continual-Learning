# Awesome-Continual-Learning

This is the paper list of our paper ``A Comprehensive Survey of Continual Learning: Theory, Method and Application''.


## Survey

- <a name="todo"></a> [2023 arXiv] Towards Label-Efficient Incremental Learning A Survey [[paper](https://arxiv.org/abs/2302.00353)]

- <a name="todo"></a> [2022 arXiv] Continual Learning of Natural Language Processing Tasks A Survey [[paper](https://arxiv.org/abs/2211.12701)]
  
- <a name="todo"></a> [2022 Trends in Neurosciences] Contributions by metaplasticity to solving the Catastrophic Forgetting Problem [[paper](https://doi.org/10.1016/j.tins.2022.06.002)]

- <a name="todo"></a> [2022 TPAMI] Class-incremental learning survey and performance evaluation on image classification [[paper](https://arxiv.org/abs/2010.15277)]

- <a name='todo'></a> [2022 NMI] Biological underpinnings for lifelong learning machines [[paper]()]

- <a name='todo'></a> [2022 Neurocomputing] Online Continual Learning in Image Classification_ An Empirical Survey [[paper]()]

- <a name='todo'></a> [2022 JAIR] Towards Continual Reinforcement Learning [[paper]()]

- <a name='todo'></a> [2021] Recent Advances of Continual Learning in Computer Vision_ An Overview [[paper]()]

- <a name='todo'></a> [2021 TPAMI] A continual learning survey_ Defying forgetting in classification tasks [[paper]()]

- <a name='todo'></a> [2021 Neural Computation] Replay in Deep Learning_ Current Approaches and Missing Biological Elements [[paper]()]

- <a name='todo'></a> [2020 Trends in Cognitive Sciences] Embracing Change_ Continual Learning in Deep Neural Networks [[paper]()]

- <a name='todo'></a> [2020 TPAMI] Class-incremental learning survey and performance evaluation on image classification [[paper]()]

- <a name='todo'></a> [2020 COLING] Continual Lifelong Learning in Natural Language Processing_ A Survey [[paper]()]
  
- <a name="todo"></a> [2019 Neural Networks] Continual Lifelong Learning with Neural Networks: A Review [[paper](https://arxiv.org/abs/1802.07569)]


## Papers

### 2023

- <a name='todo'></a> [2023 ICLR] TASK-AWARE INFORMATION ROUTING FROM COMMON REPRESENTATION SPACE IN LIFELONG LEARNING [[paper](None)]

### 2022

- <a name='todo'></a> [2022 WACV] Online Continual Learning Via Candidates Voting [[paper](https://ieeexplore.ieee.org/document/9706621/)]

- <a name='todo'></a> [2022 WACV] Knowledge Capture and Replay for Continual Learning [[paper](https://openaccess.thecvf.com/content/WACV2022/papers/Gopalakrishnan_Knowledge_Capture_and_Replay_for_Continual_Learning_WACV_2022_paper.pdf)]

- <a name='todo'></a> [2022 WACV] FeTrIL Feature Translation for Exemplar-Free Class-Incremental Learning [[paper](https://arxiv.org/abs/2211.13131)]

- <a name='todo'></a> [2022 WACV] Dataset Knowledge Transfer for Class-Incremental Learning without Memory [[paper](https://openaccess.thecvf.com/content/WACV2022/papers/Slim_Dataset_Knowledge_Transfer_for_Class-Incremental_Learning_Without_Memory_WACV_2022_paper.pdf)]

- <a name='todo'></a> [2022 TPAMI] Uncertainty-aware Contrastive Distillation for Incremental Semantic Segmentation [[paper](None)]

- <a name='todo'></a> [2022 TPAMI] MgSvF Multi-Grained Slow vs. Fast Framework for Few-Shot Class-Incremental Learning [[paper](https://ieeexplore.ieee.org/document/9645290/)]

- <a name='todo'></a> [2022 TPAMI] Few-Shot Class-Incremental Learning by Sampling Multi-Phase Tasks [[paper](https://arxiv.org/abs/2203.17030)]

- <a name='todo'></a> [2022 TPAMI] Class-Incremental Continual Learning into the eXtended DER-verse [[paper](https://arxiv.org/abs/2201.00766)]

- <a name='todo'></a> [2022 TNNLS] Self-Training for Class-Incremental Semantic Segmentation [[paper](https://pubmed.ncbi.nlm.nih.gov/35298386/)]

- <a name='todo'></a> [2022 PRL] Continual Semi-Supervised Learning through Contrastive Interpolation Consistency  [[paper](None)]

- <a name='todo'></a> [2022 NeurIPS] Task-Free Continual Learning via Online Discrepancy Distance Learning [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/95c6ae3f3393786203a4b6dcb9df1036-Abstract-Conference.html)]

- <a name='todo'></a> [2022 NeurIPS] SparCL Sparse Continual Learning on the Edge [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/80133d0f6eccaace15508f91e3c5a93c-Abstract-Conference.html)]

- <a name='todo'></a> [2022 NeurIPS] S-Prompts Learning with Pre-trained Transformers An Occamâ€™s Razor for Domain Incremental Learning [[paper](https://papers.nips.cc/paper_files/paper/2022/hash/25886d7a7cf4e33fd44072a0cd81bf30-Abstract-Conference.html)]

- <a name='todo'></a> [2022 NeurIPS] Retrospective Adversarial Replay for Continual Learning [[paper](None)]

- <a name='todo'></a> [2022 NeurIPS] Repeated Augmented Rehearsal A Simple but Strong Baseline for Online Continual Learning [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/file/5ebbbac62b968254093023f1c95015d3-Paper-Conference.pdf)]

- <a name='todo'></a> [2022 NeurIPS] On the Effectiveness of Lipschitz-Driven Rehearsal in Continual Learning [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/cf10920ac985275845247f865b452529-Abstract-Conference.html)]

- <a name='todo'></a> [2022 NeurIPS] On Reinforcement Learning and Distribution Matching for Fine-Tuning Language Models with no Catastrophic Forgetting [[paper](https://arxiv.org/abs/2206.00761)]

- <a name='todo'></a> [2022 NeurIPS] Memory Efficient Continual Learning with Transformers [[paper](https://papers.nips.cc/paper_files/paper/2022/hash/4522de4178bddb36b49aa26efad537cf-Abstract-Conference.html)]

- <a name='todo'></a> [2022 NeurIPS] Margin-Based Few-Shot Class-Incremental Learning with Class-Level Overfitting Mitigation [[paper](https://papers.nips.cc/paper_files/paper/2022/hash/ae817e85f71ef86d5c9566598e185b89-Abstract-Conference.html)]

- <a name='todo'></a> [2022 NeurIPS] LIFELONG NEURAL PREDICTIVE CODING LEARNING CUMULATIVELY ONLINE WITHOUT FORGETTING [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/26f5a4e26c13d1e0a47f46790c999361-Abstract-Conference.html)]

- <a name='todo'></a> [2022 NeurIPS] How Well Do Unsupervised Learning Algorithms Model Human Real-time and Life-long Learning [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/8dfc3a2720a4112243a285b98e0d4415-Abstract-Datasets_and_Benchmarks.html)]

- <a name='todo'></a> [2022 NeurIPS] Few-Shot Continual Active Learning by a Robot [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/c58437945392cec01e0c75ff6cef901a-Abstract-Conference.html)]

- <a name='todo'></a> [2022 NeurIPS] Exploring Example Influence in Continual Learning [[paper](None)]

- <a name='todo'></a> [2022 NeurIPS] Disentangling Transfer in Continual Reinforcement Learning [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/2938ad0434a6506b125d8adaff084a4a-Abstract-Conference.html)]

- <a name='todo'></a> [2022 NeurIPS] Continual Learning In Environments With Polynomial Mixing Times [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/89c61fce5a8b73871d1c4073f486b134-Abstract-Conference.html)]

- <a name='todo'></a> [2022 NeurIPS] Continual learning a feature extraction formalization, an efficient algorithm, and fundamental obstructions [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/b63a24a1832bd14fa945c71f535c0095-Abstract-Conference.html)]

- <a name='todo'></a> [2022 NeurIPS] CLiMB A Continual Learning Benchmark for Vision-and-Language Tasks [[paper](https://arxiv.org/abs/2206.09059)]

- <a name='todo'></a> [2022 NeurIPS] CGLB Benchmark Tasks for Continual Graph Learning [[paper](https://papers.nips.cc/paper_files/paper/2022/hash/548a41b9cac6f50dccf7e63e9e1b1b9b-Abstract-Datasets_and_Benchmarks.html)]

- <a name='todo'></a> [2022 NeurIPS] Beyond Not-Forgetting Continual Learning with Backward Knowledge Transfer [[paper](https://arxiv.org/abs/2211.00789)]

- <a name='todo'></a> [2022 NeurIPS] ALIFE Adaptive Logit Regularizer and Feature Replay for Incremental Semantic Segmentation [[paper](https://arxiv.org/abs/2210.06816)]

- <a name='todo'></a> [2022 NeurIPS] A Theoretical Study on Solving Continual Learning [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/20f44da80080d76bbc35bca0027f14e6-Abstract-Conference.html)]

- <a name='todo'></a> [2022 NeurIPSW] A Simple Baseline that Questions the Use of Pretrained-Models in Continual Learning [[paper](https://neurips.cc/virtual/2022/60478)]

- <a name='todo'></a> [2022 Neural Networks] Efficient Perturbation Inference and Expandable Network for Continual Learning [[paper](None)]

- <a name='todo'></a> [2022 NAACL] Overcoming Catastrophic Forgetting During Domain Adaptation of Seq2seq Language Generation [[paper](https://aclanthology.org/2022.naacl-main.398.pdf)]

- <a name='todo'></a> [2022 MM] Semantics-Driven Generative Replay for Few-Shot Class Incremental Learning [[paper](None)]

- <a name='todo'></a> [2022 MM] Incremental Few-Shot Semantic Segmentation via Embedding Adaptive-Update and Hyper-class Representation [[paper](https://github.com/wuyirui)]

- <a name='todo'></a> [2022 MM] Class Gradient Projection For Continual Learning [[paper](https://dl.acm.org/doi/10.1145/3503161.3548054)]

- <a name='todo'></a> [2022 IJCAI] Learning from Students_ Online Contrastive Distillation Network for General Continual Learning [[paper](https://www.ijcai.org/proceedings/2022/446)]

- <a name='todo'></a> [2022 IJCAI] DyGRAIN_ An Incremental Learning Framework for Dynamic Graphs [[paper](https://www.ijcai.org/proceedings/2022/438)]

- <a name='todo'></a> [2022 IJCAI] Continual Semantic Segmentation Leveraging Image-level Labels and Rehearsal [[paper](https://www.ijcai.org/proceedings/2022/177)]

- <a name='todo'></a> [2022 IJCAI] Continual Federated Learning Based on Knowledge Distillation [[paper](https://www.ijcai.org/proceedings/2022/303)]

- <a name='todo'></a> [2022 IJCAI] CERT_ Continual Pre-Training on Sketches for Library-Oriented Code Generation [[paper](https://www.ijcai.org/proceedings/2022/329)]

### 2021

### 2020

### 2019

### 2018

### 2017

### 2016

