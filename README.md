# Awesome-Continual-Learning

This is the paper list of our paper ``A Comprehensive Survey of Continual Learning: Theory, Method and Application''.


## Survey

- <a name="todo"></a> [2023 arXiv] A Comprehensive Survey of Continual Learning: Theory, Method and Application [[paper](https://arxiv.org/abs/2302.00487)]
  
- <a name="todo"></a> [2023 arXiv] A Survey on Incremental Update for Neural Recommender Systems [[paper](https://arxiv.org/abs/2303.02851#)]
  
- <a name="todo"></a> [2023 arXiv] Deep Class-Incremental Learning: A Survey [[paper](https://arxiv.org/abs/2302.03648)]

- <a name="todo"></a> [2023 arXiv] Towards Label-Efficient Incremental Learning A Survey [[paper](https://arxiv.org/abs/2302.00353)]

- <a name="todo"></a> [2022 arXiv] Continual Learning of Natural Language Processing Tasks A Survey [[paper](https://arxiv.org/abs/2211.12701)]
  
- <a name="todo"></a> [2022 Trends in Neurosciences] Contributions by metaplasticity to solving the Catastrophic Forgetting Problem [[paper](https://doi.org/10.1016/j.tins.2022.06.002)]

- <a name="todo"></a> [2022 TPAMI] Class-incremental learning survey and performance evaluation on image classification [[paper](https://arxiv.org/abs/2010.15277)]

- <a name='todo'></a> [2022 NMI] Biological underpinnings for lifelong learning machines [[paper](https://www.nature.com/articles/s42256-022-00452-0)]

- <a name='todo'></a> [2022 Neurocomputing] Online Continual Learning in Image Classification_ An Empirical Survey [[paper](https://arxiv.org/abs/2101.10423)]

- <a name='todo'></a> [2022 JAIR] Towards Continual Reinforcement Learning [[paper](https://arxiv.org/abs/2012.13490)]

- <a name='todo'></a> [2021 arXiv] Recent Advances of Continual Learning in Computer Vision_ An Overview [[paper](https://arxiv.org/abs/2109.11369)]

- <a name='todo'></a> [2021 TPAMI] A continual learning survey_ Defying forgetting in classification tasks [[paper](https://arxiv.org/abs/1909.08383)]

- <a name='todo'></a> [2021 Neural Computation] Replay in Deep Learning_ Current Approaches and Missing Biological Elements [[paper](https://arxiv.org/abs/2104.04132)]

- <a name='todo'></a> [2020 Trends in Cognitive Sciences] Embracing Change_ Continual Learning in Deep Neural Networks [[paper](https://www.sciencedirect.com/science/article/pii/S1364661320302199)]

- <a name='todo'></a> [2020 TPAMI] Class-incremental learning survey and performance evaluation on image classification [[paper](https://arxiv.org/abs/2010.15277)]

- <a name='todo'></a> [2020 COLING] Continual Lifelong Learning in Natural Language Processing_ A Survey [[paper](https://arxiv.org/abs/2012.09823)]
  
- <a name="todo"></a> [2019 Neural Networks] Continual Lifelong Learning with Neural Networks: A Review [[paper](https://arxiv.org/abs/1802.07569)]


## Papers

### 2023

- <a name='todo'></a> [2023 ICLR] TASK-AWARE INFORMATION ROUTING FROM COMMON REPRESENTATION SPACE IN LIFELONG LEARNING [[paper](https://arxiv.org/abs/2302.11346)]

### 2022

- <a name='todo'></a> [2022 WACV] Online Continual Learning Via Candidates Voting [[paper](https://arxiv.org/abs/2110.08855v1)]

- <a name='todo'></a> [2022 WACV] Knowledge Capture and Replay for Continual Learning [[paper](https://arxiv.org/abs/2012.06789)]

- <a name='todo'></a> [2022 WACV] FeTrIL Feature Translation for Exemplar-Free Class-Incremental Learning [[paper](https://arxiv.org/abs/2211.13131)]

- <a name='todo'></a> [2022 WACV] Dataset Knowledge Transfer for Class-Incremental Learning without Memory [[paper](https://arxiv.org/abs/2110.08421)]

- <a name='todo'></a> [2022 TPAMI] Uncertainty-aware Contrastive Distillation for Incremental Semantic Segmentation [[paper](https://arxiv.org/abs/2203.14098)]

- <a name='todo'></a> [2022 TPAMI] MgSvF Multi-Grained Slow vs. Fast Framework for Few-Shot Class-Incremental Learning [[paper](https://arxiv.org/abs/2006.15524)]

- <a name='todo'></a> [2022 TPAMI] Few-Shot Class-Incremental Learning by Sampling Multi-Phase Tasks [[paper](https://arxiv.org/abs/2203.17030)]

- <a name='todo'></a> [2022 TPAMI] Class-Incremental Continual Learning into the eXtended DER-verse [[paper](https://arxiv.org/abs/2201.00766)]

- <a name='todo'></a> [2022 TNNLS] Self-Training for Class-Incremental Semantic Segmentation [[paper](https://arxiv.org/abs/2012.03362)]

- <a name='todo'></a> [2022 PRL] Continual Semi-Supervised Learning through Contrastive Interpolation Consistency  [[paper](https://arxiv.org/abs/2108.06552)]

- <a name='todo'></a> [2022 NeurIPS] Task-Free Continual Learning via Online Discrepancy Distance Learning [[paper](https://arxiv.org/abs/2210.06579)]

- <a name='todo'></a> [2022 NeurIPS] SparCL Sparse Continual Learning on the Edge [[paper](https://arxiv.org/abs/2209.09476)]

- <a name='todo'></a> [2022 NeurIPS] S-Prompts Learning with Pre-trained Transformers An Occam’s Razor for Domain Incremental Learning [[paper](https://arxiv.org/abs/2207.12819)]

- <a name='todo'></a> [2022 NeurIPS] Retrospective Adversarial Replay for Continual Learning [[paper](https://openreview.net/forum?id=XEoih0EwCwL)]

- <a name='todo'></a> [2022 NeurIPS] Repeated Augmented Rehearsal A Simple but Strong Baseline for Online Continual Learning [[paper](https://arxiv.org/abs/2209.13917)]

- <a name='todo'></a> [2022 NeurIPS] On the Effectiveness of Lipschitz-Driven Rehearsal in Continual Learning [[paper](https://arxiv.org/abs/2210.06443)]

- <a name='todo'></a> [2022 NeurIPS] On Reinforcement Learning and Distribution Matching for Fine-Tuning Language Models with no Catastrophic Forgetting [[paper](https://arxiv.org/abs/2206.00761)]

- <a name='todo'></a> [2022 NeurIPS] Memory Efficient Continual Learning with Transformers [[paper](https://arxiv.org/abs/2203.04640)]

- <a name='todo'></a> [2022 NeurIPS] Margin-Based Few-Shot Class-Incremental Learning with Class-Level Overfitting Mitigation [[paper](https://arxiv.org/abs/2210.04524)]

- <a name='todo'></a> [2022 NeurIPS] LIFELONG NEURAL PREDICTIVE CODING LEARNING CUMULATIVELY ONLINE WITHOUT FORGETTING [[paper](https://arxiv.org/abs/1905.10696)]

- <a name='todo'></a> [2022 NeurIPS] How Well Do Unsupervised Learning Algorithms Model Human Real-time and Life-long Learning [[paper](https://openreview.net/forum?id=c0l2YolqD2T)]

- <a name='todo'></a> [2022 NeurIPS] Few-Shot Continual Active Learning by a Robot [[paper](https://arxiv.org/abs/2210.04137)]

- <a name='todo'></a> [2022 NeurIPS] Exploring Example Influence in Continual Learning [[paper](https://arxiv.org/abs/2209.12241)]

- <a name='todo'></a> [2022 NeurIPS] Disentangling Transfer in Continual Reinforcement Learning [[paper](https://arxiv.org/abs/2209.13900)]

- <a name='todo'></a> [2022 NeurIPS] Continual Learning In Environments With Polynomial Mixing Times [[paper](https://arxiv.org/abs/2112.07066)]

- <a name='todo'></a> [2022 NeurIPS] Continual learning a feature extraction formalization, an efficient algorithm, and fundamental obstructions [[paper](https://arxiv.org/abs/2203.14383)]

- <a name='todo'></a> [2022 NeurIPS] CLiMB A Continual Learning Benchmark for Vision-and-Language Tasks [[paper](https://arxiv.org/abs/2206.09059)]

- <a name='todo'></a> [2022 NeurIPS] CGLB Benchmark Tasks for Continual Graph Learning [[paper](https://openreview.net/forum?id=5wNiiIDynDF)]

- <a name='todo'></a> [2022 NeurIPS] Beyond Not-Forgetting Continual Learning with Backward Knowledge Transfer [[paper](https://arxiv.org/abs/2211.00789)]

- <a name='todo'></a> [2022 NeurIPS] ALIFE Adaptive Logit Regularizer and Feature Replay for Incremental Semantic Segmentation [[paper](https://arxiv.org/abs/2210.06816)]

- <a name='todo'></a> [2022 NeurIPS] A Theoretical Study on Solving Continual Learning [[paper](https://arxiv.org/abs/2211.02633)]

- <a name='todo'></a> [2022 NeurIPSW] A Simple Baseline that Questions the Use of Pretrained-Models in Continual Learning [[paper](https://arxiv.org/abs/2210.04428)]

- <a name='todo'></a> [2022 Neural Networks] Efficient Perturbation Inference and Expandable Network for Continual Learning [[paper](https://www.sciencedirect.com/science/article/abs/pii/S0893608022004269)]

- <a name='todo'></a> [2022 NAACL] Overcoming Catastrophic Forgetting During Domain Adaptation of Seq2seq Language Generation [[paper](https://aclanthology.org/2022.naacl-main.398.pdf)]

- <a name='todo'></a> [2022 MM] Semantics-Driven Generative Replay for Few-Shot Class Incremental Learning [[paper](https://doi.org/10.1145/3503161.3548160)]

- <a name='todo'></a> [2022 MM] Incremental Few-Shot Semantic Segmentation via Embedding Adaptive-Update and Hyper-class Representation [[paper](https://arxiv.org/abs/2207.12964)]

- <a name='todo'></a> [2022 MM] Class Gradient Projection For Continual Learning [[paper](https://doi.org/10.1145/3503161.3548054)]

- <a name='todo'></a> [2022 IJCAI] Learning from Students_ Online Contrastive Distillation Network for General Continual Learning [[paper](https://doi.org/10.24963/ijcai.2022/446)]

- <a name='todo'></a> [2022 IJCAI] DyGRAIN_ An Incremental Learning Framework for Dynamic Graphs [[paper](https://doi.org/10.24963/ijcai.2022/438)]

- <a name='todo'></a> [2022 IJCAI] Continual Semantic Segmentation Leveraging Image-level Labels and Rehearsal [[paper](https://doi.org/10.24963/ijcai.2022/177)]

- <a name='todo'></a> [2022 IJCAI] Continual Federated Learning Based on Knowledge Distillation [[paper](https://doi.org/10.24963/ijcai.2022/303)]

- <a name='todo'></a> [2022 IJCAI] CERT_ Continual Pre-Training on Sketches for Library-Oriented Code Generation [[paper](https://doi.org/10.24963/ijcai.2022/329)]

- <a name='todo'></a> [2022 ICPR] Effects of Auxiliary Knowledge on Continual Learning [[paper](https://arxiv.org/abs/2206.02577v1)]

- <a name='todo'></a> [2022 ICML] Wide Neural Networks Forget Less Catastrophically [[paper](https://arxiv.org/abs/2110.11526)]

- <a name='todo'></a> [2022 ICML] Wide Neural Networks Forget Less Catastrophically [[paper](https://arxiv.org/abs/2110.11526)]

- <a name='todo'></a> [2022 ICML] VariGrow_ Variational Architecture Growing for Task-Agnostic Continual Learning based on Bayesian Novelty [[paper](https://proceedings.mlr.press/v162/ardywibowo22a.html)]

- <a name='todo'></a> [2022 ICML] Proving Theorems using Incremental Learning and Hindsight Experience Replay [[paper](https://arxiv.org/abs/2112.10664)]

- <a name='todo'></a> [2022 ICML] Online Continual Learning through Mutual Information Maximization [[paper](https://proceedings.mlr.press/v162/guo22g.html)]

- <a name='todo'></a> [2022 ICML] NISPA_ Neuro-Inspired Stability-Plasticity Adaptation for Continual Learning in Sparse Networks [[paper](https://arxiv.org/abs/2206.09117)]

- <a name='todo'></a> [2022 ICML] Improving Task-free Continual Learning by Distributionally Robust Memory Evolution [[paper](https://arxiv.org/abs/2207.07256)]

- <a name='todo'></a> [2022 ICML] Forget-free Continual Learning with Winning Subnetworks [[paper](https://arxiv.org/abs/2303.14962)]

- <a name='todo'></a> [2022 ICML] Continual Learning with Guarantees via Weight Interval Constraints [[paper](https://arxiv.org/abs/2206.07996)]

- <a name='todo'></a> [2022 ICML] Continual Learning via Sequential Function-Space Variational Inference [[paper](https://proceedings.mlr.press/v162/rudner22a.html)]

- <a name='todo'></a> [2022 ICLR] TRGP TRUST REGION GRADIENT PROJECTION FOR CONTINUAL LEARNING [[paper](https://arxiv.org/abs/2202.02931)]

- <a name='todo'></a> [2022 ICLR] TOWARDS CONTINUAL KNOWLEDGE LEARNING OF LANGUAGE MODELS [[paper](https://arxiv.org/abs/2110.03215)]

- <a name='todo'></a> [2022 ICLR] SUBSPACE REGULARIZERS FOR FEW-SHOT CLASS INCREMENTAL LEARNING [[paper](https://arxiv.org/abs/2110.07059)]

- <a name='todo'></a> [2022 ICLR] REPRESENTATIONAL CONTINUITY FOR UNSUPERVISED CONTINUAL LEARNING [[paper](https://arxiv.org/abs/2110.06976)]

- <a name='todo'></a> [2022 ICLR] PRETRAINED LANGUAGE MODEL IN CONTINUAL LEARNING A COMPARATIVE STUDY [[paper](https://openreview.net/forum?id=figzpGMrdD)]

- <a name='todo'></a> [2022 ICLR] ONLINE CORESET SELECTION FOR REHEARSAL-BASED CONTINUAL LEARNING [[paper](https://arxiv.org/abs/2106.01085)]

- <a name='todo'></a> [2022 ICLR] ONLINE CONTINUAL LEARNING ON CLASS INCREMENTAL BLURRY TASK CONFIGURATION WITH ANYTIME INFERENCE [[paper](https://arxiv.org/abs/2110.10031)]

- <a name='todo'></a> [2022 ICLR] NEW INSIGHTS ON REDUCING ABRUPT REPRESENTATION CHANGE IN ONLINE CONTINUAL LEARNING [[paper](https://arxiv.org/abs/2104.05025)]

- <a name='todo'></a> [2022 ICLR] NEW INSIGHTS ON REDUCING ABRUPT REPRESENTA- TION CHANGE IN ONLINE CONTINUAL LEARNING [[paper](https://arxiv.org/abs/2104.05025)]

- <a name='todo'></a> [2022 ICLR] Model Zoo A Growing “Brain” That Learns Continually [[paper](https://arxiv.org/abs/2106.03027)]

- <a name='todo'></a> [2022 ICLR] MEMORY REPLAY WITH DATA COMPRESSION FOR CONTINUAL LEARNING [[paper](https://arxiv.org/abs/2202.06592)]

- <a name='todo'></a> [2022 ICLR] LOOKING BACK ON LEARNED EXPERIENCES FOR CLASS_TASK INCREMENTAL LEARNING [[paper](https://openreview.net/forum?id=RxplU3vmBx)]

- <a name='todo'></a> [2022 ICLR] LFPT5 A UNIFIED FRAMEWORK FOR LIFELONG FEW-SHOT LANGUAGE LEARNING BASED ON PROMPT TUNING OF T5 [[paper](https://arxiv.org/abs/2110.07298)]

- <a name='todo'></a> [2022 ICLR] LEARNING FAST, LEARNING SLOW A GENERAL CONTINUAL LEARNING METHOD BASED ON COMPLEMENTARY LEARNING SYSTEM [[paper](https://arxiv.org/abs/2201.12604)]

- <a name='todo'></a> [2022 ICLR] LEARNING CURVES FOR CONTINUAL LEARNING IN NEURAL NETWORKS SELF-KNOWLEDGE TRANSFER AND FORGETTING [[paper](https://arxiv.org/abs/2112.01653)]

- <a name='todo'></a> [2022 ICLR] INFORMATION-THEORETIC ONLINE MEMORY SELECTION FOR CONTINUAL LEARNING [[paper](https://arxiv.org/abs/2204.04763)]

- <a name='todo'></a> [2022 ICLR] HOW WELL DOES SELF-SUPERVISED PRE-TRAINING PERFORM WITH STREAMING DATA [[paper](https://arxiv.org/abs/2104.12081)]

- <a name='todo'></a> [2022 ICLR] EFFECT OF MODEL AND PRETRAINING SCALE ON CATASTROPHIC FORGETTING IN NEURAL NETWORKS [[paper](https://openreview.net/forum?id=GhVS8_yPeEa)]

- <a name='todo'></a> [2022 ICLR] CONTINUAL NORMALIZATION RETHINKING BATCH NORMALIZATION FOR ONLINE CONTINUAL LEARNING [[paper](https://arxiv.org/abs/2203.16102)]

- <a name='todo'></a> [2022 ICLR] CONTINUAL LEARNING WITH RECURSIVE GRADIENT OPTIMIZATION [[paper](https://arxiv.org/pdf/2201.12522.pdf)]

- <a name='todo'></a> [2022 ICLR] CONTINUAL LEARNING WITH FILTER ATOM SWAPPING [[paper](https://openreview.net/forum?id=metRpM4Zrcb)]

- <a name='todo'></a> [2022 ICLR] COMPS CONTINUAL META POLICY SEARCH [[paper](https://arxiv.org/abs/2112.04467)]

- <a name='todo'></a> [2022 ICLR] CLEVA-COMPASS A CONTINUAL LEARNING EVALUATION ASSESSMENT COMPASS TO PROMOTE RESEARCH TRANSPARENCY AND COMPARABILITY [[paper](https://arxiv.org/abs/2110.03331)]

- <a name='todo'></a> [2022 EMNLP] Continual Training of Language Models for Few-Shot Learning [[paper](https://arxiv.org/abs/2210.05549)]

- <a name='todo'></a> [2022 ECCV] Transfer without Forgetting [[paper](https://arxiv.org/abs/2206.00388)]

- <a name='todo'></a> [2022 ECCV] The Challenges of Continuous Self-Supervised Learning [[paper](https://arxiv.org/abs/2203.12710)]

- <a name='todo'></a> [2022 ECCV] S3C Self-Supervised Stochastic Classifiers for Few-Shot Class-Incremental Learning [[paper](https://arxiv.org/abs/2307.02246)]

- <a name='todo'></a> [2022 ECCV] R-DFCIL Relation-Guided Representation Learning for Data-Free Class Incremental Learning [[paper](https://arxiv.org/abs/2203.13104)]

- <a name='todo'></a> [2022 ECCV] Prototype-Guided Continual Adaptation for Class-Incremental Unsupervised Domain Adaptation [[paper](https://arxiv.org/abs/2207.10856)]

- <a name='todo'></a> [2022 ECCV] Online Task-free Continual Learning with Dynamic Sparse Distributed Memory [[paper](https://doi.org/10.1007/978-3-031-19806-9_42)]

- <a name='todo'></a> [2022 ECCV] Online Continual Learning with Contrastive Vision Transformer [[paper](https://arxiv.org/abs/2207.13516)]

- <a name='todo'></a> [2022 ECCV] Novel Class Discovery without Forgetting [[paper](http://arxiv.org/abs/2207.10659)]

- <a name='todo'></a> [2022 ECCV] Meta-Learning with Less Forgetting on Large-Scale Non-Stationary Task Distributions [[paper](https://arxiv.org/abs/2209.01501)]

- <a name='todo'></a> [2022 ECCV] Long-Tailed Class Incremental Learning [[paper](https://arxiv.org/abs/2210.00266)]

- <a name='todo'></a> [2022 ECCV] Learning with Recoverable Forgetting [[paper](https://arxiv.org/abs/2207.08224)]

- <a name='todo'></a> [2022 ECCV] Incremental Task Learning with Incremental Rank Updates [[paper](https://arxiv.org/abs/2207.09074)]

- <a name='todo'></a> [2022 ECCV] incDFM Incremental Deep Feature Modeling for Continual Novelty Detection [[paper](https://doi.org/10.1007/978-3-031-19806-9_34)]

- <a name='todo'></a> [2022 ECCV] Helpful or Harmful Inter-Task Association in Continual Learning [[paper](https://doi.org/10.1007/978-3-031-20083-0_31)]

- <a name='todo'></a> [2022 ECCV] Generative Negative Text Replay for Continual Vision-Language Pretraining [[paper](https://arxiv.org/abs/2210.17322)]

- <a name='todo'></a> [2022 ECCV] FOSTER Feature Boosting and Compression for Class-Incremental Learning [[paper](https://arxiv.org/abs/2204.04662)]

- <a name='todo'></a> [2022 ECCV] Few-Shot Class-Incremental Learning via Entropy-Regularized Data-Free Replay [[paper](https://arxiv.org/abs/2207.11213)]

- <a name='todo'></a> [2022 ECCV] Few-Shot Class-Incremental Learning from an Open-Set Perspective [[paper](https://arxiv.org/abs/2208.00147)]

- <a name='todo'></a> [2022 ECCV] DualPrompt Complementary Prompting for Rehearsal-free Continual Learning [[paper](https://arxiv.org/abs/2204.04799)]

- <a name='todo'></a> [2022 ECCV] DLCFT Deep Linear Continual Fine-Tuning for General Incremental Learning [[paper](https://arxiv.org/abs/2208.08112)]

- <a name='todo'></a> [2022 ECCV] CoSCL Cooperation of Small Continual Learners is Stronger than a Big One [[paper](https://arxiv.org/abs/2207.06543)]

- <a name='todo'></a> [2022 ECCV] Class-incremental Novel Class Discovery [[paper](https://arxiv.org/abs/2207.08605)]

- <a name='todo'></a> [2022 ECCV] Class-Incremental Learning with Cross-Space Clustering and Controlled Transfer [[paper](https://arxiv.org/abs/2208.03767)]

- <a name='todo'></a> [2022 ECCV] Balancing Stability and Plasticity through Advanced Null Space in Continual Learning [[paper](https://arxiv.org/abs/2207.12061)]

- <a name='todo'></a> [2022 ECCV] Balancing between Forgetting and Acquisition in Incremental Subpopulation Learning [[paper](https://doi.org/10.1007/978-3-031-19809-0_21)]

- <a name='todo'></a> [2022 ECCV] Anti-Retroactive Interference for Lifelong Learning [[paper](https://arxiv.org/abs/2208.12967)]

- <a name='todo'></a> [2022 CVPR] vCLIMB A Novel Video Class Incremental Learning Benchmark [[paper](https://arxiv.org/abs/2201.09381)]

- <a name='todo'></a> [2022 CVPR] Towards Better Plasticity-Stability Trade-off in Incremental Learning A Simple Linear Connector [[paper](https://arxiv.org/abs/2110.07905)]

- <a name='todo'></a> [2022 CVPR] Self-Sustaining Representation Expansion for Non-Exemplar Class-Incremental Learning [[paper](https://arxiv.org/abs/2203.06359)]

- <a name='todo'></a> [2022 CVPR] Self-Supervised Models are Continual Learners [[paper](https://arxiv.org/abs/2112.04215)]

- <a name='todo'></a> [2022 CVPR] Representation Compensation Networks for Continual Semantic Segmentation [[paper](https://arxiv.org/abs/2203.05402)]

- <a name='todo'></a> [2022 CVPR] Probing Representation Forgetting in Supervised and Unsupervised Continual Learning [[paper](https://arxiv.org/abs/2203.13381)]

- <a name='todo'></a> [2022 CVPR] Overcoming Catastrophic Forgetting in Incremental Object Detection via Elastic Response Distillation [[paper](https://arxiv.org/abs/2204.02136)]

- <a name='todo'></a> [2022 CVPR] Online Continual Learning on a Contaminated Data Stream with Blurry Task Boundaries [[paper](https://arxiv.org/abs/2203.15355)]

- <a name='todo'></a> [2022 CVPR] On Generalizing Beyond Domains in Cross-Domain Continual Learning [[paper](https://arxiv.org/abs/2203.03970)]

- <a name='todo'></a> [2022 CVPR] Not Just Selection, but Exploration Online Class-Incremental Continual Learning via Dual View Consistency [[paper](https://ieeexplore.ieee.org/abstract/document/9879220)]

- <a name='todo'></a> [2022 CVPR] Mimicking the Oracle An Initial Phase Decorrelation Approach for Class Incremental Learning [[paper](https://arxiv.org/abs/2112.04731)]

- <a name='todo'></a> [2022 CVPR] MetaFSCIL A Meta-Learning Approach for Few-Shot Class Incremental Learning [[paper](https://ieeexplore.ieee.org/document/9878925)]

- <a name='todo'></a> [2022 CVPR] Meta-attention for ViT-backed Continual Learning [[paper](https://arxiv.org/abs/2203.11684)]

- <a name='todo'></a> [2022 CVPR] Lifelong Graph Learning [[paper](https://arxiv.org/abs/2202.10688)]

- <a name='todo'></a> [2022 CVPR] Learning to Prompt for Continual Learning [[paper](https://arxiv.org/abs/2112.08654)]

- <a name='todo'></a> [2022 CVPR] Learning to Imagine Diversify Memory for Incremental Learning using Unlabeled Data [[paper](https://arxiv.org/abs/2204.08932)]

- <a name='todo'></a> [2022 CVPR] Learning Bayesian Sparse Networks with Full Experience Replay for Continual Learning [[paper](https://arxiv.org/abs/2202.10203)]

- <a name='todo'></a> [2022 CVPR] Incremental Transformer Structure Enhanced Image Inpainting with Masking Positional Encoding [[paper](https://arxiv.org/abs/2203.00867)]

- <a name='todo'></a> [2022 CVPR] Incremental Learning in Semantic Segmentation from Image Labels [[paper](https://arxiv.org/pdf/2112.01882.pdf)]

- <a name='todo'></a> [2022 CVPR] General Incremental Learning with Domain-aware Categorical Representations [[paper](https://arxiv.org/abs/2204.04078)]

- <a name='todo'></a> [2022 CVPR] GCR GRADIENT CORESET BASED REPLAY BUFFER SELECTION FOR CONTINUAL LEARNING [[paper](https://arxiv.org/abs/2111.11210)]

- <a name='todo'></a> [2022 CVPR] Forward Compatible Few-Shot Class-Incremental Learning [[paper](https://arxiv.org/abs/2203.06953)]

- <a name='todo'></a> [2022 CVPR] Few-Shot Incremental Learning for Label-to-Image Translation [[paper](https://ieeexplore.ieee.org/document/9878463)]

- <a name='todo'></a> [2022 CVPR] Federated Class-Incremental Learning [[paper](https://arxiv.org/abs/2203.11473)]

- <a name='todo'></a> [2022 CVPR] Energy-based Latent Aligner for Incremental Learning [[paper](https://arxiv.org/abs/2203.14952)]

- <a name='todo'></a> [2022 CVPR] DyTox Transformers for Continual Learning with DYnamic TOken eXpansion [[paper](https://arxiv.org/abs/2111.11326)]

- <a name='todo'></a> [2022 CVPR] Doodle It Yourself Class Incremental Learning by Drawing a Few Sketches [[paper](https://arxiv.org/abs/2203.14843)]

- <a name='todo'></a> [2022 CVPR] Continual Learning with Lifelong Vision Transformer [[paper](https://ieeexplore.ieee.org/document/9880356)]

- <a name='todo'></a> [2022 CVPR] Continual Learning for Visual Search with Backward Consistent Feature Embedding [[paper](https://arxiv.org/abs/2205.13384)]

- <a name='todo'></a> [2022 CVPR] Constrained Few-shot Class-incremental Learning [[paper](https://arxiv.org/abs/2203.16588)]

- <a name='todo'></a> [2022 CVPR] Class-Incremental Learning with Strong Pre-trained Models [[paper](https://arxiv.org/abs/2204.03634)]

- <a name='todo'></a> [2022 CVPR] Class-Incremental Learning by Knowledge Distillation with Adaptive Feature Consolidation [[paper](https://arxiv.org/abs/2204.00895)]

- <a name='todo'></a> [2022 CVPR] Bring Evanescent Representations to Life in Lifelong Class Incremental Learning [[paper](https://ieeexplore.ieee.org/document/9878745)]

- <a name='todo'></a> [2022 CVIU] Balanced softmax cross-entropy for incremental learning with and without memory [[paper](https://arxiv.org/abs/2103.12532)]

- <a name='todo'></a> [2022 COLING] Incremental Prompting_ Episodic Memory Prompt for Lifelong Event Detection [[paper](https://arxiv.org/abs/2204.07275)]

- <a name='todo'></a> [2022 COLING] Dynamic Dialogue Policy for Continual Reinforcement Learning [[paper](https://arxiv.org/abs/2204.05928)]

- <a name='todo'></a> [2022 COLING] Continual Few-shot Intent Detection [[paper](https://aclanthology.org/2022.coling-1.26/)]

- <a name='todo'></a> [2022 ACL] Overcoming Catastrophic Forgetting beyond Continual Learning_ Balanced Training for Neural Machine Translation [[paper](https://arxiv.org/abs/2203.03910)]

- <a name='todo'></a> [2022 ACL] Few-Shot Class-Incremental Learning for Named Entity Recognition [[paper](https://aclanthology.org/2022.acl-long.43/)]

- <a name='todo'></a> [2022 ACL] Continual Sequence Generation with Adaptive Compositional Modules [[paper](https://arxiv.org/abs/2203.10652)]

- <a name='todo'></a> [2022 ACL] Continual Prompt Tuning for Dialog State Tracking [[paper](https://arxiv.org/abs/2203.06654)]

- <a name='todo'></a> [2022 ACL] Continual Pre-training of Language Models for Math Problem Understanding with Syntax-Aware Memory Network [[paper](https://aclanthology.org/2022.acl-long.408/)]

- <a name='todo'></a> [2022 ACL] Continual Few-shot Relation Learning via Embedding Space Regularization and Data Augmentation [[paper](https://arxiv.org/abs/2203.02135)]

- <a name='todo'></a> [2022 ACL] ConTinTin_ Continual Learning from Task Instructions [[paper](https://arxiv.org/abs/2203.08512)]

- <a name='todo'></a> [2022 AAAI] Static-Dynamic Co-teaching for Class-Incremental 3D Object Detection [[paper](https://arxiv.org/abs/2112.07241)]

- <a name='todo'></a> [2022 AAAI] Same State, Different Task Continual Reinforcement Learning without Interference [[paper](https://arxiv.org/abs/2106.02940)]

- <a name='todo'></a> [2022 AAAI] Learngene From Open-World to Your Learning Task [[paper](https://arxiv.org/abs/2106.06788)]

- <a name='todo'></a> [2022 AAAI] Continual Learning through Retrieval and Imagination [[paper](https://doi.org/10.1609/aaai.v36i8.20837)]

- <a name='todo'></a> [2022 AAAI] Adaptive Orthogonal Projection for Batch and Online Continual Learning [[paper](https://doi.org/10.1609/aaai.v36i6.20634)]

### 2021

- <a name='todo'></a> [2021 arXiv] SPeCiaL Self-Supervised Pretraining for Continual Learning [[paper](https://arxiv.org/abs/2106.09065)]

- <a name='todo'></a> [2021 arXiv] AN EMPIRICAL INVESTIGATION OF THE ROLE OF PRE-TRAINING IN LIFELONG LEARNING [[paper](https://arxiv.org/abs/2112.09153)]

- <a name='todo'></a> [2021 WACV] Do not Forget to Attend to Uncertainty while Mitigating Catastrophic Forgetting [[paper](https://arxiv.org/abs/2102.01906)]

- <a name='todo'></a> [2021 TPAMI] Incremental Object Detection via Meta-Learning [[paper](https://arxiv.org/abs/2003.08798)]

- <a name='todo'></a> [2021 TNNLS] Triple-Memory Networks A Brain-Inspired Method for Continual Learning [[paper](https://arxiv.org/abs/2003.03143)]

- <a name='todo'></a> [2021 PRL] ACAE-REMIND for Online Continual Learning with Compressed Feature Replay [[paper](https://arxiv.org/abs/2105.08595)]

- <a name='todo'></a> [2021 NeurIPS] SSUL Semantic Segmentation with Unknown Label for Exemplar-based Class-Incremental Learning [[paper](https://arxiv.org/abs/2106.11562)]

- <a name='todo'></a> [2021 NeurIPS] RMM Reinforced Memory Management for Class-Incremental Learning [[paper](https://arxiv.org/abs/2301.05792)]

- <a name='todo'></a> [2021 NeurIPS] Posterior Meta-Replay for Continual Learning [[paper](https://arxiv.org/abs/2103.01133)]

- <a name='todo'></a> [2021 NeurIPS] Overcoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima [[paper](https://arxiv.org/abs/2111.01549)]

- <a name='todo'></a> [2021 NeurIPS] Optimizing Reusable Knowledge for Continual Learning via Metalearning [[paper](https://arxiv.org/abs/2106.05390)]

- <a name='todo'></a> [2021 NeurIPS] Natural continual learning success is a journey, not (just) a destination [[paper](https://arxiv.org/abs/2106.08085)]

- <a name='todo'></a> [2021 NeurIPS] Mitigating Forgetting in Online Continual Learning with Neuron Calibration [[paper](https://arxiv.org/abs/2211.05347)]

- <a name='todo'></a> [2021 NeurIPS] Lifelong Domain Adaptation via Consolidated Internal Distribution [[paper](https://openreview.net/forum?id=lpW-UP8VKcg)]

- <a name='todo'></a> [2021 NeurIPS] Learning where to learn Gradient sparsity in meta and continual learning [[paper](https://arxiv.org/abs/2110.14402)]

- <a name='todo'></a> [2021 NeurIPS] Gradient-based Editing of Memory Examples for Online Task-free Continual Learning [[paper](https://arxiv.org/abs/2006.15294)]

- <a name='todo'></a> [2021 NeurIPS] Generative vs Discriminative Rethinking The Meta-Continual Learning [[paper](https://openreview.net/forum?id=soDi-HkzC1)]

- <a name='todo'></a> [2021 NeurIPS] Formalizing the Generalization-Forgetting Trade-Off in Continual Learning [[paper](https://arxiv.org/abs/2109.14035)]

- <a name='todo'></a> [2021 NeurIPS] Flattening Sharpness for Dynamic Gradient Projection Memory Benefits Continual Learning [[paper](https://arxiv.org/abs/2110.04593)]

- <a name='todo'></a> [2021 NeurIPS] DualNet Continual Learning, Fast and Slow [[paper](https://arxiv.org/abs/2110.00175)]

- <a name='todo'></a> [2021 NeurIPS] Continual World_ A Robotic Benchmark For Continual Reinforcement Learning [[paper](https://arxiv.org/abs/2105.10919)]

- <a name='todo'></a> [2021 NeurIPS] Continual Learning via Local Module Composition [[paper](https://arxiv.org/abs/2111.07736)]

- <a name='todo'></a> [2021 NeurIPS] Continual Auxiliary Task Learning [[paper](https://arxiv.org/abs/2202.11133)]

- <a name='todo'></a> [2021 NeurIPS] Class-Incremental Learning via Dual Augmentation [[paper](https://openreview.net/forum?id=8dqEeFuhgMG)]

- <a name='todo'></a> [2021 NeurIPS] Bridging Non Co-occurrence with Unlabeled In-the-wild Data for Incremental Object Detection [[paper](https://arxiv.org/abs/2110.15017)]

- <a name='todo'></a> [2021 NeurIPS] BooVAE Boosting Approach for Continual Learning of VAE [[paper](https://arxiv.org/abs/1908.11853)]

- <a name='todo'></a> [2021 NeurIPS] BNS Building Network Structures Dynamically for Continual Learning [[paper](https://openreview.net/forum?id=2ybxtABV2Og)]

- <a name='todo'></a> [2021 NeurIPS] AFEC Active Forgetting of Negative Transfer in Continual Learning [[paper](https://arxiv.org/abs/2110.12187)]

- <a name='todo'></a> [2021 NeurIPS] Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning [[paper](https://arxiv.org/abs/2112.02706)]

- <a name='todo'></a> [2021 NAACL] Towards Continual Learning for Multilingual Machine Translation via Vocabulary Substitution [[paper](https://arxiv.org/abs/2103.06799)]

- <a name='todo'></a> [2021 NAACL] Continual Learning for Text Classification with Information Disentanglement Based Regularization [[paper](https://arxiv.org/abs/2104.05489v1)]

- <a name='todo'></a> [2021 NAACL] Continual Learning for Neural Machine Translation [[paper](https://aclanthology.org/2021.naacl-main.310/)]

- <a name='todo'></a> [2021 NAACL] Adapting BERT for Continual Learning of a Sequence of Aspect Sentiment Classification Tasks [[paper](https://arxiv.org/abs/2112.03271)]

- <a name='todo'></a> [2021 MM] Video Transformer for Deepfake Detection with Incremental Learning [[paper](https://arxiv.org/abs/2108.05307)]

- <a name='todo'></a> [2021 MM] Remember and Reuse_ Cross-Task Blind Image Quality Assessment via Relevance-aware Incremental Learning [[paper](https://doi.org/10.1145/3474085.3475642)]

- <a name='todo'></a> [2021 MM] Co-Transport for Class-Incremental Learning [[paper](https://arxiv.org/abs/2107.12654)]

- <a name='todo'></a> [2021 MM] An EM Framework for Online Incremental Learning of Semantic Segmentation [[paper](https://arxiv.org/abs/2108.03613)]

- <a name='todo'></a> [2021 IJCAI] TrafficStream_ A Streaming Traffic Flow Forecasting Framework Based on Graph Neural Networks and Continual Learning [[paper](https://arxiv.org/abs/2106.06273)]

- <a name='todo'></a> [2021 IJCAI] Learning with Selective Forgetting [[paper](https://doi.org/10.24963/ijcai.2021/137)]

- <a name='todo'></a> [2021 IJCAI] Knowledge Consolidation based Class Incremental Online Learning with Limited Data [[paper](https://arxiv.org/abs/2106.06795)]

- <a name='todo'></a> [2021 IJCAI] FedSpeech_ Federated Text-to-Speech with Continual Learning [[paper](https://arxiv.org/abs/2110.07216)]

- <a name='todo'></a> [2021 ICPR] Semi-Supervised Class Incremental Learning [[paper](https://ieeexplore.ieee.org/abstract/document/9413225)]

- <a name='todo'></a> [2021 ICPR] Class-incremental Learning with Pre-allocated Fixed Classifiers [[paper](https://arxiv.org/abs/2010.08657)]

- <a name='todo'></a> [2021 ICML] Variational Auto-Regressive Gaussian Processes for Continual Learning [[paper](https://arxiv.org/abs/2006.05468)]

- <a name='todo'></a> [2021 ICML] Kernel Continual Learning [[paper](https://arxiv.org/abs/2107.05757)]

- <a name='todo'></a> [2021 ICML] GP-Tree A Gaussian Process Classifier for Few-Shot Incremental Learning [[paper](https://arxiv.org/abs/2102.07868)]

- <a name='todo'></a> [2021 ICML] Federated Continual Learning with Weighted Inter-client Transfer [[paper](https://arxiv.org/abs/2003.03196)]

- <a name='todo'></a> [2021 ICML] Continuous Coordination As a Realistic Scenario for Lifelong Learning [[paper](https://arxiv.org/abs/2103.03216)]

- <a name='todo'></a> [2021 ICML] Continual Learning in the Teacher-Student Setup Impact of Task Similarity [[paper](https://arxiv.org/pdf/2107.04384.pdf)]

- <a name='todo'></a> [2021 ICML] Bayesian Structural Adaptation for Continual Learning [[paper](https://arxiv.org/abs/1912.03624)]

- <a name='todo'></a> [2021 ICLR] REMEMBERING FOR THE RIGHT REASONS EXPLANATIONS REDUCE CATASTROPHIC FORGETTING [[paper](https://openreview.net/pdf?id=tHgJoMfy6nI)]

- <a name='todo'></a> [2021 ICLR] LINEAR MODE CONNECTIVITY IN MULTITASK AND CONTINUAL LEARNING [[paper](https://arxiv.org/abs/2010.04495)]

- <a name='todo'></a> [2021 ICLR] GRADIENT PROJECTION MEMORY FOR CONTINUAL LEARNING [[paper](https://arxiv.org/abs/2103.09762)]

- <a name='todo'></a> [2021 ICLR] GENERALIZED VARIATIONAL CONTINUAL LEARNING [[paper](https://openreview.net/forum?id=_IM-AfFhna9)]

- <a name='todo'></a> [2021 ICLR] EFFICIENT CONTINUAL LEARNING WITH MODULAR NETWORKS AND TASK-DRIVEN PRIORS [[paper](https://openreview.net/forum?id=EKV158tSfwv)]

- <a name='todo'></a> [2021 ICLR] EEC LEARNING TO ENCODE AND REGENERATE IMAGES FOR CONTINUAL LEARNING [[paper](https://arxiv.org/abs/2101.04904)]

- <a name='todo'></a> [2021 ICLR] CPR CLASSIFIER-PROJECTION REGULARIZATION FOR CONTINUAL LEARNING [[paper](https://openreview.net/forum?id=F2v4aqEL6ze)]

- <a name='todo'></a> [2021 ICLR] CONTINUAL LEARNING IN RECURRENT NEURAL NETWORKS [[paper](https://openreview.net/forum?id=8xeBUgD8u9)]

- <a name='todo'></a> [2021 ICLR] CONTEXTUAL TRANSFORMATION NETWORKS FOR ONLINE CONTINUAL LEARNING [[paper](https://openreview.net/forum?id=zx_uX-BO7CH)]

- <a name='todo'></a> [2021 ICCV] Wanderlust Online Continual Object Detection in the Real World [[paper](https://arxiv.org/abs/2108.11005)]

- <a name='todo'></a> [2021 ICCV] Synthesized Feature based Few-Shot Class-Incremental Learning on a Mixture of Subspaces [[paper](https://ieeexplore.ieee.org/document/9711372)]

- <a name='todo'></a> [2021 ICCV] Striking a Balance between Stability and Plasticity for Class-Incremental Learning [[paper](https://ieeexplore.ieee.org/document/9711484)]

- <a name='todo'></a> [2021 ICCV] SS-IL Separated Softmax for Incremental Learning [[paper](https://ieeexplore.ieee.org/document/9710553)]

- <a name='todo'></a> [2021 ICCV] Rehearsal revealed The limits and merits of revisiting samples in continual learning [[paper](https://arxiv.org/abs/2104.07446)]

- <a name='todo'></a> [2021 ICCV] RECALL Replay-based Continual Learning in Semantic Segmentation [[paper](https://arxiv.org/abs/2108.03673)]

- <a name='todo'></a> [2021 ICCV] Online Continual Learning with Natural Distribution Shifts An Empirical Study with Visual Data [[paper](https://arxiv.org/abs/2108.09020)]

- <a name='todo'></a> [2021 ICCV] Generalized and Incremental Few-Shot Learning by Explicit Learning and Calibration without Forgetting [[paper](https://arxiv.org/abs/2108.08165)]

- <a name='todo'></a> [2021 ICCV] Few-Shot and Continual Learning with Attentive Independent Mechanisms [[paper](https://arxiv.org/abs/2107.14053)]

- <a name='todo'></a> [2021 ICCV] Else-Net: Elastic Semantic Network for Continual Action Recognition from Skeleton Data [[paper](https://ieeexplore.ieee.org/document/9711342)]

- <a name='todo'></a> [2021 ICCV] Detection and Continual Learning of Novel Face Presentation Attacks [[paper](https://arxiv.org/abs/2108.12081)]

- <a name='todo'></a> [2021 ICCV] Continual Prototype Evolution Learning Online from Non-Stationary Data Streams [[paper](https://arxiv.org/abs/2009.00919)]

- <a name='todo'></a> [2021 ICCV] Continual Learning on Noisy Data Streams via Self-Purified Replay [[paper](https://arxiv.org/abs/2110.07735)]

- <a name='todo'></a> [2021 ICCV] Continual Learning for Image-Based Camera Localization [[paper](https://arxiv.org/abs/2108.09112)]

- <a name='todo'></a> [2021 ICCV] Co2L Contrastive Continual Learning [[paper](https://arxiv.org/abs/2106.14413)]

- <a name='todo'></a> [2021 ICCV] Class-Incremental Learning for Action Recognition in Videos [[paper](https://arxiv.org/abs/2203.13611)]

- <a name='todo'></a> [2021 ICCV] Always Be Dreaming A New Approach for Data-Free Class-Incremental Learning [[paper](https://arxiv.org/abs/2106.09701)]

- <a name='todo'></a> [2021 EMNLP] Total Recall_ a Customized Continual Learning Method for Neural Semantic Parsers [[paper](https://arxiv.org/abs/2109.05186)]

- <a name='todo'></a> [2021 EMNLP] ECONET_ Effective Continual Pretraining of Language Models for Event Temporal Reasoning [[paper](https://arxiv.org/abs/2012.15283)]

- <a name='todo'></a> [2021 EMNLP] Continual Learning in Task-Oriented Dialogue Systems [[paper](https://arxiv.org/abs/2012.15504)]

- <a name='todo'></a> [2021 EMNLP] Continual Few-Shot Learning for Text Classification [[paper](https://aclanthology.org/2021.emnlp-main.460/)]

- <a name='todo'></a> [2021 EMNLP] CLASSIC Continual and Contrastive Learning of Aspect Sentiment Classification Tasks [[paper](https://arxiv.org/abs/2112.02714)]

- <a name='todo'></a> [2021 CVPR] Training Networks in Null Space of Feature Covariance for Continual Learning [[paper](https://arxiv.org/abs/2103.07113)]

- <a name='todo'></a> [2021 CVPR] Towards Open World Object Detection [[paper](https://arxiv.org/abs/2103.02603)]

- <a name='todo'></a> [2021 CVPR] Semantic-aware Knowledge Distillation for Few-Shot Class-Incremental Learning [[paper](https://arxiv.org/abs/2103.04059)]

- <a name='todo'></a> [2021 CVPR] Self-Promoted Prototype Refinement for Few-Shot Class-Incremental Learning [[paper](https://arxiv.org/abs/2107.08918)]

- <a name='todo'></a> [2021 CVPR] Rectification-based Knowledge Retention for Continual Learning [[paper](None)]

- <a name='todo'></a> [2021 CVPR] Rainbow Memory Continual Learning with a Memory of Diverse Samples [[paper](https://arxiv.org/abs/2103.17230)]

- <a name='todo'></a> [2021 CVPR] Prototype Augmentation and Self-Supervision for Incremental Learning [[paper](https://ieeexplore.ieee.org/document/9578909)]

- <a name='todo'></a> [2021 CVPR] PLOP Learning without Forgetting for Continual Semantic Segmentation [[paper](https://arxiv.org/abs/2011.11390)]

- <a name='todo'></a> [2021 CVPR] ORDisCo Effective and Efficient Usage of Incremental Unlabeled Data for Semi-supervised Continual Learning [[paper](https://arxiv.org/abs/2101.00407)]

- <a name='todo'></a> [2021 CVPR] On Learning the Geodesic Path for Incremental Learning [[paper](https://arxiv.org/abs/2104.08572)]

- <a name='todo'></a> [2021 CVPR] Lifelong Person Re-Identification via Adaptive Knowledge Accumulation [[paper](https://arxiv.org/abs/2103.12462)]

- <a name='todo'></a> [2021 CVPR] Layerwise Optimization by Gradient Decomposition for Continual Learning [[paper](https://arxiv.org/abs/2105.07561)]

- <a name='todo'></a> [2021 CVPR] Incremental Learning via Rate Reduction [[paper](https://arxiv.org/abs/2011.14593)]

- <a name='todo'></a> [2021 CVPR] Incremental Few-Shot Instance Segmentation [[paper](https://arxiv.org/abs/2105.05312)]

- <a name='todo'></a> [2021 CVPR] Image De-raining via Continual Learning [[paper](https://ieeexplore.ieee.org/document/9577362/)]

- <a name='todo'></a> [2021 CVPR] IIRC Incremental Implicitly-Refined Classification [[paper](https://arxiv.org/abs/2012.12477)]

- <a name='todo'></a> [2021 CVPR] Hyper-LifelongGAN Scalable Lifelong Learning for Image Conditioned Generation [[paper](https://ieeexplore.ieee.org/document/9578318)]

- <a name='todo'></a> [2021 CVPR] Few-Shot Incremental Learning with Continually Evolved Classifiers [[paper](https://arxiv.org/abs/2104.03047)]

- <a name='todo'></a> [2021 CVPR] Efficient Feature Transformations for Discriminative and Generative Continual Learning [[paper](https://arxiv.org/abs/2103.13558)]

- <a name='todo'></a> [2021 CVPR] Distilling Causal Effect of Data in Class-Incremental Learning [[paper](https://ieeexplore.ieee.org/document/9578597)]

- <a name='todo'></a> [2021 CVPR] DER Dynamically Expandable Representation for Class Incremental Learning [[paper](https://arxiv.org/abs/2103.16788)]

- <a name='todo'></a> [2021 CVPR] Continual Semantic Segmentation via Repulsion-Attraction of Sparse and Disentangled Latent Representations [[paper](https://arxiv.org/abs/2103.06342)]

- <a name='todo'></a> [2021 CVPR] Continual Learning via Bit-Level Information Preserving [[paper](https://arxiv.org/abs/2105.04444v1)]


### 2020

### 2019

### 2018

### 2017

### 2016

